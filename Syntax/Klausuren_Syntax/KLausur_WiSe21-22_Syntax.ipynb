{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***'Syntax natürlicher Sprachen',*** **Wintersemester 2021/22**\n",
    "\n",
    "--- \n",
    "# Klausur: Syntax natürlicher Sprachen *(15.02.2022)*\n",
    "\n",
    "- **Bearbeitungszeitraum: 10:15-11:45**\n",
    "- **Abgabe in Moodle bis 12:00**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übersicht\n",
    "\n",
    "- [Hinweise zur Bearbeitung](#Hinweise-zur-Bearbeitung)\n",
    "- [Laden von Paketen](#Laden-von-Paketen)\n",
    "\n",
    "\n",
    "1. [Ambiguität in Konstituentengrammatik](#1.-Ambiguität-in-Konstituentengrammatik)\n",
    "2. [Ambiguität in Dependenzgrammatik](#2.-Ambiguität-in-Dependenzgrammatik)\n",
    "3. [Konstituenten- und Adjunkttests](#3.-Konstituenten--und-Adjunkttests)\n",
    "4. [CFG Analysen](#4.-CFG-Analysen)\n",
    "5. [Dependenzanalyse](#5.-Dependenzanalyse)\n",
    "6. [FCFG-Erweiterung: Kasus, Agreement, Subkategorisierung](#6.-FCFG-Erweiterung:-Kasus,-Agreement,-Subkategorisierung)\n",
    "7. [Slash-Kategorien, Inversion, Wortstellung](#7.-Slash-Kategorien,-Inversion,-Wortstellung)\n",
    "8. [Syntaxregeln komplexer Sätze](#8.-Syntaxregeln-komplexer-Sätze)\n",
    "9. [Parsing-Algorithmen und Rekursionstypen](#9.-Parsing-Algorithmen-und-Rekursionstypen)\n",
    "10. [Unifikationsparsing](#10.-Unifikationsparsing-und-getypte-Merkmalstrukturen)\n",
    "11. [Statistisches Parsing](#11.-Statistisches-Parsing)\n",
    "12. [Datengestützte Syntaxanalyse](#12.-Datengestützte-Syntaxanalyse)\n",
    "13. [Chunk-Analysen](#13.-Chunk-Analysen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweise zur Bearbeitung\n",
    "\n",
    "### Falls noch nicht geschehen, benennen Sie bitte zunächst die Datei der Klausur-Angabe nach folgendem Schema um: \n",
    "\n",
    " #### `Nachname_Vorname_Matrikelnummer.ipynb`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie nun in folgender Codezelle die letzte Ziffer Ihrer Matrikelnummer ein (`last_number`) und führen Sie die Codezelle aus, um Ihre Gruppennummer zu berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_number = \n",
    "\n",
    "group_number = int((((last_number*3)%10)/3.5))+1\n",
    "print(\"Ihre Gruppennummer: \"+str(group_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## *WICHTIG: Bearbeiten Sie in den Aufgaben, in denen explizit darauf hingewiesen wird, nur die Aufgabenstellung, die Ihnen gemäß Ihrer Gruppennummer zugeordnet wird!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Hinweise zum Ausfüllen der Codezellen\n",
    "\n",
    "### Wenn gegeben, führen Sie zunächst die mit `#RUN` markierten Codezellen zu Beginn einer Aufgabe aus (dies ist für eine erfolgreiche Bearbeitung der Aufgabe notwendig).\n",
    "\n",
    "### Verändern Sie nur die `#TO_DO`-Codezellen (nur gemäß der Angabe in der jeweiligen Aufgabe)!\n",
    "\n",
    "### Führen Sie `#TO_DO`-Codezellen nach Bearbeitung aus, um das Output ihrer Lösung zu generieren (dieses muss als Teil Ihrer Lösung mit abgespeichert werden); bei aufeinander aufbauenden Aufgaben (`a)`, `b)`usw.) ist zudem  notwendig, dass Sie Ihre Lösung aus der vorangehenden Teilaufgabe ausführen, damit diese in der folgenden zur Verfügung steht.\n",
    "\n",
    "### Angegebene Inhalte (Grammatikregeln usw.) dürfen nicht auskommentiert oder gelöscht werden, außer dies wird explizit anders erwähnt!\n",
    "\n",
    "\n",
    "### WICHTIG: Setzen Sie den Status des Notebooks ggf. auf `Trusted`, damit alle angegebenen Outputs korrekt angezeigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweis zur Bewertung\n",
    "\n",
    "### *Jede korrekt gelöste Teilaufgabe (`#TO_DO`-Codezelle) wird mit 2 Punkten bewertet.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Laden von Paketen\n",
    "\n",
    "### Führen Sie zu Beginn folgende Codezelle aus.\n",
    "\n",
    "### Das erfolgreiche Ausführen dieser Codezelle ist Voraussetzung für die Bearbeitung der folgenden Aufgaben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie diese Code-Zelle aus:)\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk import FeatStruct\n",
    "import itertools\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "def transform_nr_conll(sent_nr):\n",
    "    sent_list = []\n",
    "    for line in list(filter(None, sent_nr.split(\"\\n\"))):\n",
    "        line_list = line.split()\n",
    "        line_list.pop(0)\n",
    "        line_list.insert(1,\"_\")\n",
    "        sent_list.append(\" \".join([i for i in line_list[0:]]))\n",
    "\n",
    "    return \"\\n\".join([i for i in sent_list[0:]])\n",
    "\n",
    "\n",
    "\n",
    "from nltk import DependencyGraph\n",
    "from itertools import chain\n",
    "\n",
    "def _tree_labeled(self, i):\n",
    "        node = self.get_by_address(i)\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]        \n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "\n",
    "        if deps:\n",
    "            return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "        else:\n",
    "            return word+'('+rel+')'\n",
    "        \n",
    "def tree_labeled(self):\n",
    "        node = self.root\n",
    "\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]\n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "        return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "\n",
    "DependencyGraph._tree_labeled = _tree_labeled\n",
    "DependencyGraph.tree_labeled = tree_labeled\n",
    "\n",
    "\n",
    "\n",
    "def displacy_dep_input(sent):\n",
    "    deps = []\n",
    "    for dep in sent.split('\\n'):\n",
    "        deps.append(dep.split())\n",
    "\n",
    "    deps = [x for x in deps if x]\n",
    "\n",
    "    ex = []\n",
    "    word_list = []\n",
    "    arc_list = []\n",
    "\n",
    "    for index, dep in enumerate(deps):\n",
    "        word_list.append({\"text\": dep[0], \"tag\": \"\"})\n",
    "        line = index+1\n",
    "        head = int(dep[2])\n",
    "        label = dep[3]\n",
    "        if head>line:\n",
    "            start = index\n",
    "            end = head-1\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            start = head-1\n",
    "            end = index  \n",
    "            direction = \"right\"\n",
    "        if(label.lower() != \"root\"):\n",
    "            arc_list.append({\"start\": start, \"end\": end, \"label\": label, \"dir\": direction})\n",
    "\n",
    "    ex.append({\n",
    "        \"words\": word_list,\n",
    "        \"arcs\": arc_list\n",
    "    })    \n",
    "\n",
    "    return ex\n",
    "\n",
    "\n",
    "\n",
    "from nltk.featstruct import Feature, UnificationFailure, FeatStructReader\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_sanity_constraints(th):\n",
    "    for type1, type2 in itertools.product(th, th):\n",
    "        if type1 in th[type2] and type2 in th[type1]:\n",
    "            if type1 != type2:\n",
    "                raise ValueError(\n",
    "                    \"The type hierarchy is not antisymmetric! \" +\n",
    "                    \"{} subsumes {} and vice versa!\".format(\n",
    "                        type1, type2\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "def refl_trans_closure(type_hierarchy):\n",
    "    # make everything a set\n",
    "    # and compute reflexive closure\n",
    "    closure = defaultdict(set)\n",
    "    for t in type_hierarchy:\n",
    "        closure[t] = set(type_hierarchy[t])\n",
    "        closure[t].add(t)\n",
    "\n",
    "    # compute transitive closure\n",
    "    still_changes = True\n",
    "    while still_changes:\n",
    "        still_changes = False\n",
    "        for x in closure:\n",
    "            new_for_x = set()\n",
    "            for y in closure[x]:\n",
    "                for z in closure[y]:\n",
    "                    new_for_x.add(z)\n",
    "            len_before = len(closure[x])\n",
    "            closure[x].update(new_for_x)\n",
    "            still_changes |= len(closure[x]) > len_before\n",
    "\n",
    "    return closure\n",
    "\n",
    "\n",
    "class HierarchicalFeature(Feature):\n",
    "    def __init__(self, name, type_hierarchy, **kwargs):\n",
    "        super(HierarchicalFeature, self).__init__(name, **kwargs)\n",
    "\n",
    "        self.hierarchy = refl_trans_closure(type_hierarchy)\n",
    "        check_sanity_constraints(self.hierarchy)\n",
    "\n",
    "    def unify_base_values(self, fval1, fval2, bindings):\n",
    "        candidates = self.hierarchy[fval1].intersection(self.hierarchy[fval2])\n",
    "        score = {t: 0 for t in candidates}\n",
    "        for type1, type2 in itertools.product(candidates, candidates):\n",
    "            if type1 in self.hierarchy[type2]:\n",
    "                score[type1] += 1\n",
    "\n",
    "        return min(candidates, key=score.__getitem__, default=UnificationFailure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[zurück zur Übersicht](#Übersicht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Ambiguität in Konstituentengrammatik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gegeben sei folgender Satz: \n",
    "\n",
    "***time flies like an arrow***\n",
    "\n",
    "### Schreiben Sie zu diesem *Beispielsatz für syntaktische Ambiguität*  eine minimale CFG, die genau die intendierte Struktur des Satzes erkennt.\n",
    "\n",
    "### Folgende *intendierte Struktur* soll dabei gemäß Ihrer Gruppennummer modelliert werden:\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > ***time (flies like an arrow)VP***\n",
    "#### `Gruppe 2` > ***time flies (like an arrow)VP***\n",
    "#### `Gruppe 3` > ***(time flies like an arrow)VP***\n",
    "\n",
    "\n",
    "\n",
    "### Testen Sie anschließend Ihre Grammatik (nur die erwünschte Analyse wird ausgegeben).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (1):*\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Ambiguität in Dependenzgrammatik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gegeben sei wieder folgender Satz: \n",
    "\n",
    "***time flies like an arrow***\n",
    "\n",
    "\n",
    "### Schreiben Sie nun eine minimale ungelabelte Dependenzgrammatik, die genau die intendierte Struktur des Satzes erkennt.\n",
    "\n",
    "### Folgende *intendierte Struktur* soll dabei nun gemäß Ihrer Gruppennummer modelliert werden:\n",
    "\n",
    "#### `Gruppe 1` > ***(time flies like an arrow)VP***\n",
    "#### `Gruppe 2` > ***time (flies like an arrow)VP***\n",
    "#### `Gruppe 3` > ***time flies (like an arrow)VP***\n",
    "\n",
    "\n",
    "### Testen Sie anschließend Ihre Grammatik (nur die erwünschte Analyse wird ausgegeben).\n",
    "\n",
    "\n",
    "### *Verwenden Sie die TIGER-Dependenzregeln!*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"time flies like an arrow\"\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 3. Konstituenten- und Adjunkttests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Permutationstest\n",
    "\n",
    "#### Gegeben sei folgender Satz sowie die Permutationen seiner Satzglieder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('bei ihm', 'ist', 'der Groschen', 'gefallen')\n",
      "1 ('bei ihm', 'ist', 'gefallen', 'der Groschen')\n",
      "2 ('bei ihm', 'der Groschen', 'ist', 'gefallen')\n",
      "3 ('bei ihm', 'der Groschen', 'gefallen', 'ist')\n",
      "4 ('bei ihm', 'gefallen', 'ist', 'der Groschen')\n",
      "5 ('bei ihm', 'gefallen', 'der Groschen', 'ist')\n",
      "6 ('ist', 'bei ihm', 'der Groschen', 'gefallen')\n",
      "7 ('ist', 'bei ihm', 'gefallen', 'der Groschen')\n",
      "8 ('ist', 'der Groschen', 'bei ihm', 'gefallen')\n",
      "9 ('ist', 'der Groschen', 'gefallen', 'bei ihm')\n",
      "10 ('ist', 'gefallen', 'bei ihm', 'der Groschen')\n",
      "11 ('ist', 'gefallen', 'der Groschen', 'bei ihm')\n",
      "12 ('der Groschen', 'bei ihm', 'ist', 'gefallen')\n",
      "13 ('der Groschen', 'bei ihm', 'gefallen', 'ist')\n",
      "14 ('der Groschen', 'ist', 'bei ihm', 'gefallen')\n",
      "15 ('der Groschen', 'ist', 'gefallen', 'bei ihm')\n",
      "16 ('der Groschen', 'gefallen', 'bei ihm', 'ist')\n",
      "17 ('der Groschen', 'gefallen', 'ist', 'bei ihm')\n",
      "18 ('gefallen', 'bei ihm', 'ist', 'der Groschen')\n",
      "19 ('gefallen', 'bei ihm', 'der Groschen', 'ist')\n",
      "20 ('gefallen', 'ist', 'bei ihm', 'der Groschen')\n",
      "21 ('gefallen', 'ist', 'der Groschen', 'bei ihm')\n",
      "22 ('gefallen', 'der Groschen', 'bei ihm', 'ist')\n",
      "23 ('gefallen', 'der Groschen', 'ist', 'bei ihm')\n"
     ]
    }
   ],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "sentence = [\"bei ihm\", \"ist\", \"der Groschen\", \"gefallen\"]\n",
    "\n",
    "permutations = list(itertools.permutations(sentence))\n",
    "for (i, item) in enumerate(permutations):\n",
    "    print(i, item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus.\n",
    "\n",
    "### Geben Sie (über den Listenindex) eine Permutation des Satzes an, welche folgendes Satzglied als Konstituente bestätigt und die gleichzeitig der *Nebensatzwortstellung* entspricht (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Subjekt\n",
    "#### `Gruppe 2` > Adverbial\n",
    "#### `Gruppe 3` > finites Verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "list(itertools.permutations(sentence))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "list(itertools.permutations(sentence))[0]\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 3.2 Adjunkttest\n",
    "\n",
    "\n",
    "#### Gegeben sei folgender Satz, dessen drittes Satzglied den Averbialsatz-Test nicht besteht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sie fuhren los, während sie um 9 Uhr waren'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"sie\", \"fuhren\", \"um 9 Uhr\", \"los\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] +  \" \" + sentence[3] + \", während sie \" + sentence[2] + \" waren\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie (unter Erhalt der Wohlgeformtheit des Ausgangssatzes) ein alternatives drittes Satzglied an (an Stelle des TODO), so dass der Averbialsatz-Test erfolgreich ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sie fuhren los, während sie TODO waren'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = [\"sie\", \"fuhren\", \"TODO\", \"los\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] +  \" \" + sentence[3] + \", während sie \" + sentence[2] + \" waren\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = [\"sie\", \"fuhren\", \"TODO\", \"los\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] +  \" \" + sentence[3] + \", während sie \" + sentence[2] + \" waren\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. CFG-Analysen\n",
    "\n",
    "#### Gegeben sei folgender Satz und eine entsprechende Grammatik:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         S         \n",
      "     ┌───┴─────┐    \n",
      "     NP        VP  \n",
      " ┌───┴───┐     │    \n",
      "Det      N     V   \n",
      " │       │     │    \n",
      "die     Frau wartet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"die Frau wartet\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"die\"\n",
    "    N   -> \"Frau\"\n",
    "    V   -> \"wartet\"    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Ergänzen Sie den Satz der Angabe, so dass er ein \n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Kasusadverbial  (Adjunkt)\n",
    "#### `Gruppe 2` > präpositionales Adverbial  (Adjunkt)\n",
    "#### `Gruppe 3` > Präpositionalobjekt (Komplement)\n",
    "\n",
    "\n",
    "### enthält (Zuordnung gemäß Gruppennummer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"die Frau wartet TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Erweitern Sie die Grammatik um entsprechende lexikalische und syntaktische Regeln für den erweiterten Satz.  Halten Sie sich dabei in den ergänzten verbalen Regeln an das X-Bar-Schema!\n",
    "\n",
    "#### Verwenden Sie `VERBAL` als Symbol für `V'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"die\"\n",
    "    N   -> \"Frau\"\n",
    "    V   -> \"wartet\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"die Frau wartet TODO\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"die\"\n",
    "    N   -> \"Frau\"\n",
    "    V   -> \"wartet\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Dependenzanalyse\n",
    "\n",
    "### Analysieren Sie die Dependenzbeziehungen Ihres Beispielsatzes aus der Aufgabe 4a) im UD-Schema. Verwenden Sie das aus der Vorlesung bekannte Format: \n",
    "\n",
    "- pro Zeile: `Position, Wort, Position des Kopfes, Dependenzrelation`\n",
    "- Wurzelknoten: `Position des Kopfes` = 0, `Dependenzrelation` = ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(ROOT)\n",
      "   │    \n",
      " x(dep)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"98be5663a05645198e755fc6bd0ff168-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">x</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-98be5663a05645198e755fc6bd0ff168-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-98be5663a05645198e755fc6bd0ff168-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (5):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. FCFG-Erweiterung: Kasus, Agreement, Subkategorisierung\n",
    "\n",
    "#### Gegeben sei folgende Grammatik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    VP -> V NP NP\n",
    "    NP   -> Pron    \n",
    "\n",
    "    Pron -> \"er\" | \"dir\" |  \"es\"\n",
    "    V    -> \"schenkt\" | \"hilft\" | \"schenken\" | \"helfen\" \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Grammatik erkennt u.a. folgende, grammatisch korrekte Sätze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              S           \n",
      " ┌────────────┴───┐        \n",
      " │                VP      \n",
      " │      ┌─────────┼────┐   \n",
      " NP     │         NP   NP \n",
      " │      │         │    │   \n",
      "Pron    V        Pron Pron\n",
      " │      │         │    │   \n",
      " er  schenkt      es  dir \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er schenkt es dir\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S           \n",
      " ┌─────┴────┐       \n",
      " │          VP     \n",
      " │     ┌────┴───┐   \n",
      " NP    │        NP \n",
      " │     │        │   \n",
      "Pron   V       Pron\n",
      " │     │        │   \n",
      " er  hilft     dir \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er hilft dir\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Geben Sie einen nach den Regeln der deutschen Grammatik nicht-wohlgeformten Satz an, der fälschlicherweise von der oben angegebenen Grammatik erkannt wird, obwohl er gegen das folgende Constraint verstößt (Zuordnung gemäß Gruppennummer): \n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Subkategorisierung (Anzahl der Argumente)\n",
    "#### `Gruppe 2` > Objekt-Kasus\n",
    "#### `Gruppe 3` > Subjekt-Verb-Agreement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "neg_sentence = \"\"\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b) Erweitern Sie die angegebene Grammatik um die notwendigen Merkmale, um die Überproduktion aus 6a) zu verhindern.  Die korrekten Sätzen von oben sollen dabei weiter von der Grammatik erkannt werden (Codezelle `POSITIVTESTS`).\n",
    "\n",
    "##### Die Erweiterung muss nur die Überproduktion bzgl. des gemäß Ihrer Gruppenzuordnung zu betrachtenden Constraints verhindern!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    VP -> V NP NP\n",
    "    NP   -> Pron    \n",
    "\n",
    "    Pron -> \"er\" | \"dir\" |  \"es\"\n",
    "    V    -> \"schenkt\" | \"hilft\" | \"schenken\" | \"helfen\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=1)\n",
    "\n",
    "#NEGATIVBEISPIEL (neg_sentence aus 6a):\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (POSITIVTESTS):\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"er schenkt es dir\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    \n",
    "sentence = \"er hilft dir\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "neg_sentence = \"\"\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    VP -> V NP NP\n",
    "    NP   -> Pron    \n",
    "\n",
    "    Pron -> \"er\" | \"dir\" |  \"es\"\n",
    "    V    -> \"schenkt\" | \"hilft\" | \"schenken\" | \"helfen\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=1)\n",
    "\n",
    "#NEGATIVBEISPIEL (neg_sentence aus 6a):\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Slash-Kategorien, Inversion, Wortstellung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgender Satz und eine FCFG, die die Subjekt-VP-Inversion für den Fragesatz sowie das Herausbewegen des Fragepronomens modelliert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S[+QUEST]                    \n",
      "   ┌───────────────┴──────────┐              \n",
      "   │                     S[+INV]/NP[]       \n",
      "   │               ┌──────────┴─────────┐    \n",
      "   │           VP[]/NP[]               NP[] \n",
      "   │      ┌────────┴──────────┐         │    \n",
      "QPron[]  V[]              NP[]/NP[]   Pron[]\n",
      "   │      │                   │         │    \n",
      " woran  glaubt               ...        er  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"woran glaubt er\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S[+QUEST] -> QPron S[+INV]/NP\n",
    "    S[+INV]/?x -> VP/?x NP\n",
    "    VP/?x -> V NP/?x\n",
    "    NP/NP -> \n",
    "\n",
    "    NP -> Pron\n",
    "    \n",
    "    QPron   -> \"woran\"\n",
    "    V   -> \"glaubt\"\n",
    "    Pron   -> \"er\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kopieren Sie die Regel(n) aus obenstehender Grammatik herunter, die das folgende implementiert/implementieren (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Subjekt-VP-Inversion\n",
    "#### `Gruppe 2` > Gap-Introduction\n",
    "#### `Gruppe 3` > Gap-Realisierung\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (7):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Syntaxregeln komplexer Sätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 CFG-Regeln für komplexe Sätze\n",
    "\n",
    "#### Gegeben sei folgender Satz sowie eine kleine CFG-Grammatik, die u.a. diesen Satz erkennt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S             \n",
      " ┌─────┴─────┐        \n",
      " │           VP      \n",
      " │     ┌─────┴────┐   \n",
      " NP    │          NP \n",
      " │     │          │   \n",
      "PRON   V         PRON\n",
      " │     │          │   \n",
      "sie  glaubt     daran\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"sie glaubt daran\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    NP   -> PRON    \n",
    "\n",
    "    PRON -> \"sie\" | \"daran\" | \"dich\" | \"wer\"\n",
    "    V    -> \"glaubt\" | \"kennt\" | \"kennen\"\n",
    "    PTCL -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 a) Passen Sie den Satz so an, dass er einen:\n",
    "\n",
    "#### `Gruppe 1` > Subjektsatz\n",
    "#### `Gruppe 2` > Infinitiv-Objektsatz\n",
    "#### `Gruppe 3` > finiten Objektsatz\n",
    "\n",
    "\n",
    "### enthält (Zuordnung gemäß Gruppennummer).\n",
    "\n",
    "### Greifen Sie ausschließlich auf die in der Grammatik vorhandenen Lexeme zurück!\n",
    "\n",
    "\n",
    "#### (Satzzeichen müssen nicht berücksichtigt werden!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \" sie glaubt daran \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 b) Erweitern Sie die Grammatik um entsprechende syntaktische Regeln für Ihren  Satz aus 8.1a.\n",
    "\n",
    "\n",
    "- Verwenden Sie nur die bestehenden sowie ggf. `SBAR` und `Comp` als neue Nonterminale\n",
    "- X-Bar-Schema ist nicht notwendig (orientieren Sie sich an den Penn-Treebank-Regeln für komplexe Sätze)\n",
    "\n",
    "##### Beachten Sie die invertierte Wortstellung im Nebensatz (Verbendstellung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    NP   -> PRON    \n",
    "\n",
    "    PRON -> \"sie\" | \"daran\" | \"dich\" | \"wer\"\n",
    "    V    -> \"glaubt\" | \"kennt\" | \"kennen\"\n",
    "    PTCL -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \" sie glaubt daran \"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    VP   -> V NP\n",
    "    NP   -> PRON    \n",
    "\n",
    "    PRON -> \"sie\" | \"daran\" | \"dich\" | \"wer\"\n",
    "    V    -> \"glaubt\" | \"kennt\" | \"kennen\"\n",
    "    PTCL -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8.2. Analysieren Sie die Dependenzbeziehungen des folgenden Satzes im UD-Schema (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "#### `Gruppe 1`: *wer etwas wagt gewinnt*\n",
    "\n",
    "#### `Gruppe 2`: *er wagt zu spielen*\n",
    "\n",
    "#### `Gruppe 3`: *er wagt dass er spielt*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(ROOT)\n",
      "   │    \n",
      " x(dep)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1f9a012efcef4b3688b8328d1adabe74-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">x</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1f9a012efcef4b3688b8328d1adabe74-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1f9a012efcef4b3688b8328d1adabe74-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Parsing-Algorithmen und Rekursionstypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Ändern Sie in folgender Grammatik die Reihenfolge der Regeln, so dass der verwendete Shift-Reduce-Parser auch ohne Backtracking eine Ableitung findet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Adj -> 'old' will never be used\n",
      "Warning: N -> 'man' will never be used\n",
      "Parsing 'the old man the boat'\n",
      "    [ * the old man the boat]\n",
      "    [ 'the' * old man the boat]\n",
      "    [ Det 'old' * man the boat]\n",
      "    [ Det Adj 'man' * the boat]\n",
      "    [ Det Adj N 'the' * boat]\n",
      "    [ Det Adj N Det 'boat' * ]\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"the old man the boat\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N\n",
    "    VP -> V NP\n",
    "\n",
    "    Det -> 'the'\n",
    "    Adj -> 'old'\n",
    "    N -> 'man'\n",
    "    N -> 'boat'\n",
    "    N -> 'old'\n",
    "    V -> 'man'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ShiftReduceParser(grammar,trace=1)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"the old man the boat\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N\n",
    "    VP -> V NP\n",
    "\n",
    "    Det -> 'the'\n",
    "    Adj -> 'old'\n",
    "    N -> 'man'\n",
    "    N -> 'boat'\n",
    "    N -> 'old'\n",
    "    V -> 'man'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ShiftReduceParser(grammar,trace=1)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 9.2 Geben Sie (genau) eine rekursive CFG-Regel an, die mit einem Recursive-Descent-Parser verarbeitet werden kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Unifikationsparsing und getypte Merkmalstrukturen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 10.1 Unifikation und Merkmalsstrukturen\n",
    "\n",
    "#### Gegeben seien folgende (unifizierende) Merkmalsstrukturen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       [ NUM  = [ PL = True ] ] ]\n",
      "[ AGR = [                      ] ]\n",
      "[       [ PERS = 1             ] ]\n"
     ]
    }
   ],
   "source": [
    "f1 = FeatStruct(\"[AGR=[NUM=[+PL],PERS=1]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Geben Sie eine Merkmalsstruktur `f2` an, die ***nicht*** mit `f1`unifiziert (print-Ausgabe: None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "f1 = FeatStruct(\"[AGR=[NUM=[+PL],PERS=1]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = FeatStruct(\"[AGR=[NUM=[+PL],PERS=1]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 10.2 Unifikation mit Typen\n",
    "\n",
    "#### Gegeben sei folgende Typhierarchie:\n",
    "\n",
    "$$\\bot \\sqsubseteq \\text{Genitiv}$$\n",
    "$$\\bot \\sqsubseteq \\text{nicht-Genitiv}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Nominativ-Akkusativ}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Dativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Nominativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Akkusativ}$$\n",
    "\n",
    "####  Sie wird (mit abgekürzten Typnamen) durch das `*CASE*`-Feature implementiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "type_hierarchy = {\n",
    "    \"nichtGen\": [\"NomAkk\", \"Dat\"],\n",
    "    \"NomAkk\": [\"Nom\", \"Akk\"],\n",
    "    \"Dat\": [],\n",
    "    \"Akk\": [],\n",
    "    \"Gen\": [],\n",
    "    \"Nom\": []\n",
    "}\n",
    "CASE = HierarchicalFeature(\"CASE\", type_hierarchy)\n",
    "reader = FeatStructReader(features=(CASE,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus, um die Typhierarchie zu laden.\n",
    "\n",
    "### Geben Sie zwei Merkmalstrukturen  `f2` und `f3` an, sodass gilt:\n",
    "\n",
    "`f1` subsumiert `f2`, `f2` subsumiert `f3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "f1 = reader.fromstring(\"[*CASE*=nichtGen]\")\n",
    "f2 = reader.fromstring(\"[]\")\n",
    "f3 = reader.fromstring(\"[]\")\n",
    "print(f1.subsumes(f2), f2.subsumes(f3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = reader.fromstring(\"[*CASE*=nichtGen]\")\n",
    "f2 = reader.fromstring(\"[]\")\n",
    "f3 = reader.fromstring(\"[]\")\n",
    "print(f1.subsumes(f2), f2.subsumes(f3)) \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Statistisches Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 11.1 PCFG: Gewichte und Ableitungswahrscheinlichkeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgende Mini-Treebank aus NP-Fragmenten mit Koordinationsambiguität:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              NP            \n",
      "  ┌───────────┴────┐         \n",
      "  │                NP       \n",
      "  │      ┌─────────┼─────┐   \n",
      "  │      │         │    CONJ\n",
      "  │      │         │     │   \n",
      "kleine Hunde     Katzen und \n",
      "\n",
      "             NP             \n",
      "        ┌────┴────┬─────┐    \n",
      "        NP       CONJ   NP  \n",
      "  ┌─────┴────┐    │     │    \n",
      "kleine     Hunde und  Katzen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treestrings = [\n",
    "\"(NP kleine (NP Hunde (CONJ und) Katzen))\",\n",
    "\"(NP (NP kleine Hunde) (CONJ und) (NP Katzen))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "for tree in trees:\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passen Sie diese Mini-Treebank durch Duplizieren einer minimalen Anzahl an NP-Strukturen so an, dass die daraus induzierte Grammatik einen engen Skopus des Adjektivs (`kleine Hunde`) bevorzugt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP -> 'kleine' NP [0.2]\n",
      "NP -> 'Hunde' CONJ 'Katzen' [0.2]\n",
      "CONJ -> 'und' [1.0]\n",
      "NP -> NP CONJ NP [0.2]\n",
      "NP -> 'kleine' 'Hunde' [0.2]\n",
      "NP -> 'Katzen' [0.2]\n",
      "(NP kleine (NP Hunde (CONJ und) Katzen)) (p=0.04)\n",
      "              NP            \n",
      "  ┌───────────┴────┐         \n",
      "  │                NP       \n",
      "  │      ┌─────────┼─────┐   \n",
      "  │      │         │    CONJ\n",
      "  │      │         │     │   \n",
      "kleine Hunde     Katzen und \n",
      "\n",
      "(NP kleine (NP Hunde (CONJ und) Katzen)) (p=0.04)\n",
      "              NP            \n",
      "  ┌───────────┴────┐         \n",
      "  │                NP       \n",
      "  │      ┌─────────┼─────┐   \n",
      "  │      │         │    CONJ\n",
      "  │      │         │     │   \n",
      "kleine Hunde     Katzen und \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "treestrings = [\n",
    "\"(NP kleine (NP Hunde (CONJ und) Katzen))\",\n",
    "\"(NP (NP kleine Hunde) (CONJ und) (NP Katzen))\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('NP')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "treestrings = [\n",
    "\"(NP kleine (NP Hunde (CONJ und) Katzen))\",\n",
    "\"(NP (NP kleine Hunde) (CONJ und) (NP Katzen))\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('NP')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11.2 Übergangsbasierter Shift-Reduce-Dependency-Parser\n",
    "\n",
    "#### Gegeben sei folgender Dependenzgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"75decab8831c4a45bdde092e50882c41-0\" class=\"displacy\" width=\"450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">b</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">c</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">d</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-75decab8831c4a45bdde092e50882c41-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-75decab8831c4a45bdde092e50882c41-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M145.0,104.0 L153.0,92.0 137.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-75decab8831c4a45bdde092e50882c41-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-75decab8831c4a45bdde092e50882c41-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-75decab8831c4a45bdde092e50882c41-0-2\" stroke-width=\"2px\" d=\"M70,102.0 C70,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-75decab8831c4a45bdde092e50882c41-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 a 0 ROOT \n",
    "2 b 1 RIGHTARC-?\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 1 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie eine deutschen oder englischen Satz an, der diese Dependenzstrukturanalyse erfüllt; geben Sie außerdem die Reihenfolge der Durchführung der REDUCE-Übergänge mit einem Shift-Reduce-Dependency-Parser an. \n",
    "\n",
    "#### (Ersetzen Sie ausschließlich die Buchstaben `a,b,c,d` mit entsprechenden Wörtern sowie das Fragezeichen mit der Angaben der Nummer der Durchführung des REDUCE-Schritts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9e6a0eeab81b4780bd15f32c449b077a-0\" class=\"displacy\" width=\"450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">b</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">c</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">d</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9e6a0eeab81b4780bd15f32c449b077a-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9e6a0eeab81b4780bd15f32c449b077a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M145.0,104.0 L153.0,92.0 137.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9e6a0eeab81b4780bd15f32c449b077a-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9e6a0eeab81b4780bd15f32c449b077a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9e6a0eeab81b4780bd15f32c449b077a-0-2\" stroke-width=\"2px\" d=\"M70,102.0 C70,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9e6a0eeab81b4780bd15f32c449b077a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 a 0 ROOT \n",
    "2 b 1 RIGHTARC-?\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 1 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 a 0 ROOT \n",
    "2 b 1 RIGHTARC-?\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 1 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Datengestützte Syntaxanalyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 12.1 Lexikalisierte CFG (mit Merkmalen)\n",
    "\n",
    "#### Gegeben sei folgende FCFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[]\n",
      "  (NP[] (N[] er))\n",
      "  (VP[] (V[] erklimmt) (NP[] (Det[] den) (N[] Berg))))\n",
      "              S[]                \n",
      " ┌─────────────┴────┐             \n",
      " │                 VP[]          \n",
      " │      ┌───────────┴────┐        \n",
      "NP[]    │               NP[]     \n",
      " │      │           ┌────┴────┐   \n",
      "N[]    V[]        Det[]      N[] \n",
      " │      │           │         │   \n",
      " er  erklimmt      den       Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] NP[]\n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    V[]   -> \"erklimmt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie über ein HEAD-Merkmal in der FCFG eine vollständige Kopfannotation durch.\n",
    "\n",
    "#### (Sie können ggf. sowohl die UD als auch die TIGER-Dependenzregeln verwenden.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] NP[]    \n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    V[]   -> \"erklimmt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] NP[]    \n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    V[]   -> \"erklimmt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 12.2 Parent Annotation (mit Symbolerweiterung)\n",
    "\n",
    "#### Gegeben sei wieder folgende CFG:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              S              \n",
      " ┌────────────┴───┐           \n",
      " │                VP         \n",
      " │     ┌──────────┴───┐       \n",
      " NP    │              NP     \n",
      " │     │          ┌───┴───┐   \n",
      " N     V         Det      N  \n",
      " │     │          │       │   \n",
      " er erklimmt     den     Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    V   -> \"erklimmt\"        \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie über Symbolerweiterung (mit `^` als Trennerzeichen) in der CFG eine vollständige *Parent Annotation* durch, wie Sie durch die Regelanwendungen im Syntaxbaum der Angabe impliziert ist. \n",
    "\n",
    "##### Ergänzen Sie ggf. auch Regeln, die für eine vollständige Parent-Annotation notwendig sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    V   -> \"erklimmt\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er erklimmt den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    V   -> \"erklimmt\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Chunk-Analysen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 13.1 Geben Sie einen folgende *IOB-Tag-Sequenz* einer VP-NP-Chunk-Analyse erfüllenden deutschen Satz an, indem Sie die TODOs mit entsprechenden Strings ersetzen (nehmen Sie keine weiteren Änderungen vor).\n",
    "\n",
    "#### (Beachten Sie auch die gegebenen Satzzeichen bzgl. möglicher Satztypen und entsprechender Worstellung.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B-VP', 'TODO'),\n",
       " ('B-NP', 'TODO'),\n",
       " ('B-NP', 'TODO'),\n",
       " ('I-NP', 'TODO'),\n",
       " ('O', ','),\n",
       " ('O', 'TODO'),\n",
       " ('B-NP', 'TODO'),\n",
       " ('B-NP', 'TODO'),\n",
       " ('B-VP', 'TODO'),\n",
       " ('O', '!')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "iob_list = [\n",
    "(\"B-VP\", \"TODO\"), \n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"I-NP\", \"TODO\"),\n",
    "(\"O\", \",\"),\n",
    "(\"O\", \"TODO\"),    \n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-VP\", \"TODO\"),\n",
    "(\"O\", \"!\")\n",
    "]\n",
    "\n",
    "iob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (13.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "iob_list = [\n",
    "(\"B-VP\", \"TODO\"), \n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"I-NP\", \"TODO\"),\n",
    "(\"O\", \",\"),\n",
    "(\"O\", \"TODO\"),    \n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-NP\", \"TODO\"),\n",
    "(\"B-VP\", \"TODO\"),\n",
    "(\"O\", \"!\")\n",
    "]\n",
    "\n",
    "iob_list\n",
    "</code>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
