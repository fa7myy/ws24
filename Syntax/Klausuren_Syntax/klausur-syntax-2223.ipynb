{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***'Syntax natürlicher Sprachen',*** **Wintersemester 2022/23**\n",
    "\n",
    "--- \n",
    "# Klausur: Syntax natürlicher Sprachen *(14.02.2023)*\n",
    "\n",
    "- **Bearbeitungszeitraum: 10:15-11:45**\n",
    "- **Abgabe in Moodle bis 12:00**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übersicht\n",
    "\n",
    "- [Hinweise zur Bearbeitung](#Hinweise-zur-Bearbeitung)\n",
    "- [Laden von Paketen](#Laden-von-Paketen)\n",
    "\n",
    "\n",
    "1. [Ambiguität in Konstituentengrammatik](#1.-Ambiguität-in-Konstituentengrammatik)\n",
    "2. [Ambiguität in Dependenzgrammatik](#2.-Ambiguität-in-Dependenzgrammatik)\n",
    "3. [Konstituenten- und Adjunkttests](#3.-Konstituenten--und-Adjunkttests)\n",
    "4. [CFG Analysen](#4.-CFG-Analysen)\n",
    "5. [Dependenzanalyse](#5.-Dependenzanalyse)\n",
    "6. [Feature-based-Grammar](#6.-Feature-based-Grammar)\n",
    "7. [Slash-Kategorien](#7.-Slash-Kategorien)\n",
    "8. [Syntaxregeln komplexer Sätze](#8.-Syntaxregeln-komplexer-Sätze)\n",
    "9. [Parsing-Algorithmen und Rekursionstypen](#9.-Parsing-Algorithmen-und-Rekursionstypen)\n",
    "10. [Unifikationsparsing](#10.-Unifikationsparsing-und-getypte-Merkmalstrukturen)\n",
    "11. [Statistisches Parsing](#11.-Statistisches-Parsing)\n",
    "12. [Datengestützte Syntaxanalyse](#12.-Datengestützte-Syntaxanalyse)\n",
    "13. [Chunk-Analysen](#13.-Chunk-Analysen)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweise zur Bearbeitung\n",
    "\n",
    "### Falls noch nicht geschehen, benennen Sie bitte zunächst die Datei der Klausur-Angabe nach folgendem Schema um: \n",
    "\n",
    " #### `Nachname_Vorname_Matrikelnummer.ipynb`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie nun in folgender Codezelle die letzte Ziffer Ihrer Matrikelnummer ein (`last_number`) und führen Sie die Codezelle aus, um Ihre Gruppennummer zu berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_number = \n",
    "\n",
    "group_number = int((((last_number*3-2)%10)/4.0))+1\n",
    "print(\"Ihre Gruppennummer: \"+str(group_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## *WICHTIG: Bearbeiten Sie in den Aufgaben, in denen explizit darauf hingewiesen wird, nur die Aufgabenstellung, die Ihnen gemäß Ihrer Gruppennummer zugeordnet wird!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Hinweise zum Ausfüllen der Codezellen\n",
    "\n",
    "### Wenn gegeben, führen Sie zunächst die mit `#RUN` markierten Codezellen zu Beginn einer Aufgabe aus (dies ist für eine erfolgreiche Bearbeitung der Aufgabe notwendig).\n",
    "\n",
    "### Verändern Sie nur die `#TO_DO`-Codezellen (nur gemäß der Angabe in der jeweiligen Aufgabe)!\n",
    "\n",
    "### Führen Sie `#TO_DO`-Codezellen nach Bearbeitung aus, um das Output ihrer Lösung zu generieren (dieses muss als Teil Ihrer Lösung mit abgespeichert werden); bei aufeinander aufbauenden Aufgaben (`a)`, `b)`usw.) ist zudem  notwendig, dass Sie Ihre Lösung aus der vorangehenden Teilaufgabe ausführen, damit diese in der folgenden zur Verfügung steht.\n",
    "\n",
    "### Angegebene Inhalte (Grammatikregeln usw.) dürfen nicht auskommentiert oder gelöscht werden, außer dies wird explizit anders erwähnt!\n",
    "\n",
    "\n",
    "### WICHTIG: Setzen Sie den Status des Notebooks ggf. auf `Trusted`, damit alle angegebenen Outputs korrekt angezeigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweis zur Bewertung\n",
    "\n",
    "### *Jede korrekt gelöste Teilaufgabe (`#TO_DO`-Codezelle) wird mit 2 Punkten bewertet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Laden von Paketen\n",
    "\n",
    "### Führen Sie zu Beginn folgende Codezelle aus.\n",
    "\n",
    "### Das erfolgreiche Ausführen dieser Codezelle ist Voraussetzung für die Bearbeitung der folgenden Aufgaben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie diese Code-Zelle aus:)\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk import FeatStruct\n",
    "import itertools\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "def transform_nr_conll(sent_nr):\n",
    "    sent_list = []\n",
    "    for line in list(filter(None, sent_nr.split(\"\\n\"))):\n",
    "        line_list = line.split()\n",
    "        line_list.pop(0)\n",
    "        line_list.insert(1,\"_\")\n",
    "        sent_list.append(\" \".join([i for i in line_list[0:]]))\n",
    "\n",
    "    return \"\\n\".join([i for i in sent_list[0:]])\n",
    "\n",
    "\n",
    "\n",
    "from nltk import DependencyGraph\n",
    "from itertools import chain\n",
    "\n",
    "def _tree_labeled(self, i):\n",
    "        node = self.get_by_address(i)\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]        \n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "\n",
    "        if deps:\n",
    "            return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "        else:\n",
    "            return word+'('+rel+')'\n",
    "        \n",
    "def tree_labeled(self):\n",
    "        node = self.root\n",
    "\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]\n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "        return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "\n",
    "DependencyGraph._tree_labeled = _tree_labeled\n",
    "DependencyGraph.tree_labeled = tree_labeled\n",
    "\n",
    "\n",
    "\n",
    "def displacy_dep_input(sent):\n",
    "    deps = []\n",
    "    for dep in sent.split('\\n'):\n",
    "        deps.append(dep.split())\n",
    "\n",
    "    deps = [x for x in deps if x]\n",
    "\n",
    "    ex = []\n",
    "    word_list = []\n",
    "    arc_list = []\n",
    "\n",
    "    for index, dep in enumerate(deps):\n",
    "        word_list.append({\"text\": dep[0], \"tag\": \"\"})\n",
    "        line = index+1\n",
    "        head = int(dep[2])\n",
    "        label = dep[3]\n",
    "        if head>line:\n",
    "            start = index\n",
    "            end = head-1\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            start = head-1\n",
    "            end = index  \n",
    "            direction = \"right\"\n",
    "        if(label.lower() != \"root\"):\n",
    "            arc_list.append({\"start\": start, \"end\": end, \"label\": label, \"dir\": direction})\n",
    "\n",
    "    ex.append({\n",
    "        \"words\": word_list,\n",
    "        \"arcs\": arc_list\n",
    "    })    \n",
    "\n",
    "    return ex\n",
    "\n",
    "\n",
    "\n",
    "from nltk.featstruct import Feature, UnificationFailure, FeatStructReader\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_sanity_constraints(th):\n",
    "    for type1, type2 in itertools.product(th, th):\n",
    "        if type1 in th[type2] and type2 in th[type1]:\n",
    "            if type1 != type2:\n",
    "                raise ValueError(\n",
    "                    \"The type hierarchy is not antisymmetric! \" +\n",
    "                    \"{} subsumes {} and vice versa!\".format(\n",
    "                        type1, type2\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "def refl_trans_closure(type_hierarchy):\n",
    "    # make everything a set\n",
    "    # and compute reflexive closure\n",
    "    closure = defaultdict(set)\n",
    "    for t in type_hierarchy:\n",
    "        closure[t] = set(type_hierarchy[t])\n",
    "        closure[t].add(t)\n",
    "\n",
    "    # compute transitive closure\n",
    "    still_changes = True\n",
    "    while still_changes:\n",
    "        still_changes = False\n",
    "        for x in closure:\n",
    "            new_for_x = set()\n",
    "            for y in closure[x]:\n",
    "                for z in closure[y]:\n",
    "                    new_for_x.add(z)\n",
    "            len_before = len(closure[x])\n",
    "            closure[x].update(new_for_x)\n",
    "            still_changes |= len(closure[x]) > len_before\n",
    "\n",
    "    return closure\n",
    "\n",
    "\n",
    "class HierarchicalFeature(Feature):\n",
    "    def __init__(self, name, type_hierarchy, **kwargs):\n",
    "        super(HierarchicalFeature, self).__init__(name, **kwargs)\n",
    "\n",
    "        self.hierarchy = refl_trans_closure(type_hierarchy)\n",
    "        check_sanity_constraints(self.hierarchy)\n",
    "\n",
    "    def unify_base_values(self, fval1, fval2, bindings):\n",
    "        candidates = self.hierarchy[fval1].intersection(self.hierarchy[fval2])\n",
    "        score = {t: 0 for t in candidates}\n",
    "        for type1, type2 in itertools.product(candidates, candidates):\n",
    "            if type1 in self.hierarchy[type2]:\n",
    "                score[type1] += 1\n",
    "\n",
    "        return min(candidates, key=score.__getitem__, default=UnificationFailure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[zurück zur Übersicht](#Übersicht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Ambiguität in Konstituentengrammatik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gegeben sei folgender Satz des Englischen (*lower case*, ohne Satzzeichen): \n",
    "\n",
    "***will will will the will***\n",
    "\n",
    "### Schreiben Sie zu diesem *Beispielsatz für syntaktische Ambiguität*  eine minimale CFG, die genau die intendierte Struktur des Satzes erkennt.\n",
    "\n",
    "### Folgende *intendierte Struktur* soll dabei gemäß Ihrer Gruppennummer modelliert werden:\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > **Fragesatz:**  *Wird Will das Testament vererben?*\n",
    "#### `Gruppe 2` und `Gruppe 3` > **Aussagesatz:**  *Will wird das Testament vererben.*\n",
    "\n",
    "\n",
    "\n",
    "### Testen Sie anschließend Ihre Grammatik (nur die erwünschte Analyse wird ausgegeben).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"will will will the will\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\n",
    "PROPN -> 'will'\n",
    "N -> 'will'\n",
    "V -> 'will'\n",
    "AUX -> 'will'\n",
    "DET -> 'the'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (1):*\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"will will will the will\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\n",
    "PROPN -> 'will'\n",
    "N -> 'will'\n",
    "V -> 'will'\n",
    "AUX -> 'will'\n",
    "DET -> 'the'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Ambiguität in Dependenzgrammatik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gegeben sei wieder folgender Satz des Englischen\n",
    "\n",
    "***will will will the will***\n",
    "\n",
    "### sowie eine ungelabelte Dependenzgrammatik, die aufgrund der lexikalischen Ambiguität von *will* eine große Menge an Ableitungen produziert.\n",
    "\n",
    "### Wählen sie über den Listenindex (an Stelle des TODO)  aus den ersten 5 Ableitungsbäumen der Grammatik den Baum aus, der folgende Struktur modelliert (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > **Aussagesatz:**  *Will wird das Testament vererben.*\n",
    "#### `Gruppe 2` und `Gruppe 3` > **Fragesatz:**  *Wird Will das Testament vererben?*\n",
    "\n",
    "\n",
    "### *Dabei soll der Baum den TIGER-Dependenzregeln entsprechen!*\n",
    "\n",
    "\n",
    "### Führen Sie dazu zunächst folgende Codezelle aus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (will (will (will will) the)) \n",
      "\n",
      "    will     \n",
      "     │        \n",
      "    will     \n",
      " ┌───┴────┐   \n",
      " │       will\n",
      " │        │   \n",
      "the      will\n",
      "\n",
      "1 (will will (will (will the))) \n",
      "\n",
      "     will     \n",
      " ┌────┴────┐   \n",
      " │        will\n",
      " │         │   \n",
      " │        will\n",
      " │         │   \n",
      "will      the \n",
      "\n",
      "2 (will (will will) the will) \n",
      "\n",
      "    will     \n",
      " ┌───┼────┐   \n",
      " │   │   will\n",
      " │   │    │   \n",
      "the will will\n",
      "\n",
      "3 (will (will (will will)) the) \n",
      "\n",
      "    will     \n",
      " ┌───┴────┐   \n",
      " │       will\n",
      " │        │   \n",
      " │       will\n",
      " │        │   \n",
      "the      will\n",
      "\n",
      "4 (will (will (will will) the)) \n",
      "\n",
      "    will     \n",
      "     │        \n",
      "    will     \n",
      " ┌───┴────┐   \n",
      " │       will\n",
      " │        │   \n",
      "the      will\n",
      "\n",
      "5 (will will will (will the)) \n",
      "\n",
      "     will     \n",
      " ┌────┼────┐   \n",
      " │    │   will\n",
      " │    │    │   \n",
      "will will the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "sentence = \"will will will the will\"\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'will' -> 'will'\n",
    "    'will' -> 'the'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "trees = list(parser.parse(sentence.split()))\n",
    "\n",
    "for (i, tree) in enumerate(trees):\n",
    "    print(i, tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    if i > 4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "tree = trees[TODO]\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "tree = trees[TODO]\n",
    "tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 3. Konstituenten- und Adjunkttests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Eliminierungstest\n",
    "\n",
    "#### Gegeben sei folgender Satz sowie die Resulte der systematischen Elimierung eines Wortes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['schreibt', 'es', 'ihr', 'heute']\n",
      "1 ['er', 'es', 'ihr', 'heute']\n",
      "2 ['er', 'schreibt', 'ihr', 'heute']\n",
      "3 ['er', 'schreibt', 'es', 'heute']\n",
      "4 ['er', 'schreibt', 'es', 'ihr']\n"
     ]
    }
   ],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "sentence = [\"er\", \"schreibt\", \"es\", \"ihr\", \"heute\"]\n",
    "\n",
    "sentencelist = []\n",
    "for i in range(len((sentence))):\n",
    "    sentencelist.append(sentence.copy())\n",
    "    sentencelist[i].pop(i)\n",
    "    print(i, sentencelist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus.\n",
    "\n",
    "### Geben Sie über den Listenindex (an Stelle des TODO) eine Version des Satzes mit Eliminierung an, welche folgendes Satzglied als fakultativen bzw. optionalen Dependenten feststellt (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Objekt\n",
    "#### `Gruppe 2` > indirektes Objekt\n",
    "#### `Gruppe 3` > Adverbial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentencelist[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentencelist[TODO]\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.2 Geschehenstest\n",
    "\n",
    "\n",
    "#### Gegeben sei wieder obiger Satz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"er\", \"schreibt\", \"es\", \"ihr\", \"heute\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie über den Listenindex (an Stelle des TODO) ein eliminierbares Satzglied an, das über den Geschehenstest als  Komplement festgestellt wird:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = [\"er\", \"schreibt\", \"es\", \"ihr\", \"heute\"]\n",
    "sentence[0] + \" \" + sentence[1] + \", und das geschieht \" + sentence[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = [\"er\", \"schreibt\", \"es\", \"ihr\", \"heute\"]\n",
    "sentence[0] + \" \" + sentence[1] + \", und das geschieht \" + sentence[TODO]\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. CFG-Analysen\n",
    "\n",
    "#### Gegeben sei folgender Satz, zusätzlich eine rudimentäre Grammatik:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      S          \n",
      " ┌────┴─────┐     \n",
      " │          VP   \n",
      " │          │     \n",
      " NP       VERBAL \n",
      " │          │     \n",
      "PRON        V    \n",
      " │          │     \n",
      " er      schreibt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er schreibt\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> VERBAL\n",
    "    VERBAL -> V\n",
    "    NP  -> PRON\n",
    "\n",
    "    PRON -> \"er\" | \"es\" | \"ihr\"\n",
    "    V    -> \"schreibt\"    \n",
    "    ADV  -> \"heute\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Ergänzen Sie den Satz der Angabe mit den in der Grammatik gegebenen Terminalen, so dass er ein: \n",
    "\n",
    "\n",
    "#### `Gruppe 1` > indirektes Objekt\n",
    "#### `Gruppe 2` > Adverbial\n",
    "#### `Gruppe 3` > Objekt\n",
    "\n",
    "### enthält (Zuordnung gemäß Gruppennummer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"er schreibt TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Erweitern Sie die Grammatik um entsprechende syntaktische Regeln für den erweiterten Satz.  Halten Sie sich dabei in den ergänzten verbalen Regeln an das X-Bar-Schema!\n",
    "\n",
    "#### Beachten Sie, dass Sie zuvor die Codezelle von 4a) ausgeführt haben müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      S          \n",
      " ┌────┴─────┐     \n",
      " │          VP   \n",
      " │          │     \n",
      " NP       VERBAL \n",
      " │          │     \n",
      "PRON        V    \n",
      " │          │     \n",
      " er      schreibt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> VERBAL\n",
    "    VERBAL -> V\n",
    "    NP  -> PRON\n",
    "\n",
    "    PRON -> \"er\" | \"es\" | \"ihr\"\n",
    "    V    -> \"schreibt\"    \n",
    "    ADV  -> \"heute\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er schreibt TODO\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> VERBAL\n",
    "    VERBAL -> V\n",
    "    NP  -> PRON\n",
    "\n",
    "    PRON -> \"er\" | \"es\" | \"ihr\"\n",
    "    V    -> \"schreibt\"    \n",
    "    ADV  -> \"heute\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Dependenzanalyse\n",
    "\n",
    "### Analysieren Sie die Dependenzbeziehungen untenstehender Sätze im UD-Schema (Zuordnung gemäß Gruppennummer). Verwenden Sie das aus der Vorlesung bekannte Format: \n",
    "\n",
    "- pro Zeile: `Position, Wort, Position des Kopfes, Dependenzrelation`\n",
    "- Wurzelknoten: `Position des Kopfes` = 0, `Dependenzrelation` = ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### `Gruppe 1` > ***Josef Konrad ist Prokurist einer Bank***\n",
    "#### `Gruppe 2` > ***Der Wächter Franz verkündet ihm seine Verhaftung***\n",
    "#### `Gruppe 3` > ***Frau Grubach ist Josefs Vermieterin***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(ROOT)\n",
      "   │    \n",
      " x(dep)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"de0f8201b2604210b4cd6541d844aeb3-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">x</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de0f8201b2604210b4cd6541d844aeb3-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de0f8201b2604210b4cd6541d844aeb3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (5):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Feature-based-Grammar\n",
    "\n",
    "#### Gegeben sei folgende Grammatik mit VP-Regeln für transitive und intransitive Verben sowie einer Regel für rekursives Attachment von NP-Adjunkten an VPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    VP  -> VP NP\n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"jagt\" | \"rennt\" \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Komplement vs. Adjunkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Grammatik erkennt u.a. folgende, grammatisch korrekte Sätze, aber fürt jeweils zu Übergenerierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S                     \n",
      "     ┌─────────┴────────┐             \n",
      "     │                  VP           \n",
      "     │         ┌────────┴────┐        \n",
      "     NP        VP            NP      \n",
      " ┌───┴───┐     │    ┌────────┼─────┐  \n",
      "DET      N     V   DET      ADJ    N \n",
      " │       │     │    │        │     │  \n",
      "der     Hund rennt den     ganzen Tag\n",
      "\n",
      "               S                     \n",
      "     ┌─────────┴────────┐             \n",
      "     │                  VP           \n",
      "     │         ┌────────┴────┐        \n",
      "     NP        │             NP      \n",
      " ┌───┴───┐     │    ┌────────┼─────┐  \n",
      "DET      N     V   DET      ADJ    N \n",
      " │       │     │    │        │     │  \n",
      "der     Hund rennt den     ganzen Tag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund rennt den ganzen Tag\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              S                      \n",
      "     ┌────────┴────┐                  \n",
      "     │             VP                \n",
      "     │        ┌────┴───┐              \n",
      "     NP       VP       NP            \n",
      " ┌───┴───┐    │    ┌───┴───────┐      \n",
      "DET      N    V   DET          N     \n",
      " │       │    │    │           │      \n",
      "der     Hund jagt den     Briefträger\n",
      "\n",
      "              S                      \n",
      "     ┌────────┴────┐                  \n",
      "     │             VP                \n",
      "     │        ┌────┴───┐              \n",
      "     NP       │        NP            \n",
      " ┌───┴───┐    │    ┌───┴───────┐      \n",
      "DET      N    V   DET          N     \n",
      " │       │    │    │           │      \n",
      "der     Hund jagt den     Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erweitern Sie die angegebene Grammatik um die notwendigen Merkmale, um für die beiden Sätze jeweils die Überproduktion zu verhindern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    VP  -> VP NP\n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"jagt\" | \"rennt\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"der Hund rennt den ganzen Tag\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    \n",
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    VP  -> VP NP\n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"jagt\" | \"rennt\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"der Hund rennt den ganzen Tag\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    \n",
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Kasus-Feature\n",
    "\n",
    "#### Folgende Grammatik enthält Regeln für transitive Verben, inkl. Regeln für eine invertierte Worstellung (d.h. mit Subjekt-NP satzfinal).\n",
    "\n",
    "### Erweitern Sie diese Grammatik um die notwendigen Merkmale, um auch im folgenden Beispielsatz die Überproduktion auszuschließen:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                S                    \n",
      "            ┌───┴─────────────┐       \n",
      "            VP                │      \n",
      "      ┌─────┴────────┐        │       \n",
      "      NP             VP       NP     \n",
      " ┌────┼─────────┐    │    ┌───┴───┐   \n",
      "DET  ADJ        N    V   DET      N  \n",
      " │    │         │    │    │       │   \n",
      "den ganzen     Tag rennt der     Hund\n",
      "\n",
      "            S                    \n",
      "      ┌─────┴─────────┐           \n",
      "      │               VP         \n",
      "      │          ┌────┴───┐       \n",
      "      NP         VP       NP     \n",
      " ┌────┼─────┐    │    ┌───┴───┐   \n",
      "DET  ADJ    N    V   DET      N  \n",
      " │    │     │    │    │       │   \n",
      "den ganzen Tag rennt der     Hund\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> VP NP\n",
    "\n",
    "    S   -> VP NP\n",
    "    VP  -> NP VP\n",
    "    \n",
    "    VP  -> V\n",
    "\n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"rennt\" \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"den ganzen Tag rennt der Hund\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S[]                      \n",
      "              ┌────┴───────────────┐        \n",
      "             VP[]                  │       \n",
      "        ┌─────┴─────────┐          │        \n",
      "       NP[]            VP[]       NP[]     \n",
      "  ┌─────┼──────────┐    │     ┌────┴────┐   \n",
      "DET[] ADJ[]       N[]  V[]  DET[]      N[] \n",
      "  │     │          │    │     │         │   \n",
      " den  ganzen      Tag rennt  der       Hund\n",
      "\n",
      "             S[]                      \n",
      "        ┌─────┴──────────┐             \n",
      "        │               VP[]          \n",
      "        │          ┌─────┴────┐        \n",
      "       NP[]       VP[]       NP[]     \n",
      "  ┌─────┼─────┐    │     ┌────┴────┐   \n",
      "DET[] ADJ[]  N[]  V[]  DET[]      N[] \n",
      "  │     │     │    │     │         │   \n",
      " den  ganzen Tag rennt  der       Hund\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> VP NP\n",
    "\n",
    "    S   -> VP NP\n",
    "    VP  -> NP VP\n",
    "    \n",
    "    VP  -> V\n",
    " \n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"rennt\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"den ganzen Tag rennt der Hund\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> VP NP\n",
    "\n",
    "    S   -> VP NP\n",
    "    VP  -> NP VP\n",
    "    \n",
    "    VP  -> V\n",
    " \n",
    "    NP  -> DET N\n",
    "    NP  -> DET ADJ N \n",
    "\n",
    "    DET -> \"der\" | \"den\"\n",
    "    ADJ -> \"ganzen\"\n",
    "    N   -> \"Hund\" | \"Briefträger\" | \"Tag\"\n",
    "    V   -> \"rennt\" \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "sentence = \"den ganzen Tag rennt der Hund\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Slash-Kategorien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgender Satz und eine FCFG, die das Herausbewegen des Fragepronomens des Subjektsatzes als COMP der SBAR-Regel modelliert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          S[]                                \n",
      "                   ┌───────┴────────────────────────┐         \n",
      "                 SBAR[]                             │        \n",
      "  ┌────────────────┴───────┐                        │         \n",
      "  │                     S[]/NP[]                    │        \n",
      "  │        ┌───────────────┴──────┐                 │         \n",
      "  │        │                     VP[]               │        \n",
      "  │        │               ┌──────┴─────┐           │         \n",
      "  │        │              NP[]          │          VP[]      \n",
      "  │        │               │            │      ┌────┴─────┐   \n",
      "COMP[] NP[]/NP[]         PRON[]        V[]   COP[]      ADJ[]\n",
      "  │        │               │            │      │          │   \n",
      " wer      ...              es         glaubt  wird      selig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"wer es glaubt wird selig\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S -> SBAR VP\n",
    "    VP -> COP ADJ\n",
    "    \n",
    "    SBAR -> COMP S/NP\n",
    "    S/?x -> NP/?x VP\n",
    "    NP/NP -> \n",
    "    \n",
    "    VP -> NP V\n",
    "\n",
    "    NP -> PRON\n",
    "    \n",
    "    COMP -> \"wer\"\n",
    "    V   -> \"glaubt\"\n",
    "    PRON   -> \"es\" \n",
    "    COP  -> \"wird\"\n",
    "    ADJ -> \"selig\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kopieren Sie die Regel(n) aus obenstehender Grammatik herunter, die das folgende implementiert (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "\n",
    "\n",
    "#### `Gruppe 1` > Herunterreichen der Gap-Information\n",
    "#### `Gruppe 2` > Gap-Introduction\n",
    "#### `Gruppe 3` > Gap-Realisierung\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (7):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Syntaxregeln komplexer Sätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 CFG-Regeln für komplexe Sätze\n",
    "\n",
    "#### Gegeben sei folgender Satz sowie eine CFG-Grammatik, die u.a. diesen Satz erkennt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S                 \n",
      " ┌───────────┴───┐              \n",
      " │               VP            \n",
      " │     ┌─────────┴───┐          \n",
      " NP    │             VP        \n",
      " │     │         ┌───┴─────┐    \n",
      "PRON   V         TO        V   \n",
      " │     │         │         │    \n",
      " er  glaubt      zu     träumen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er glaubt zu träumen\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    NP   -> PRON\n",
    "    \n",
    "    VP   -> V VP    \n",
    "    VP   -> TO V \n",
    "\n",
    "    PRON -> \"er\"\n",
    "    V    -> \"glaubt\" | \"glauben\" | \"träumt\" |\"träumen\" | \"fliegt\" | \"fliegen\"\n",
    "    TO   -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 a) Geben Sie einen neuen Satz an, der einen *finiten Objektsatz* enthält. \n",
    "\n",
    "### Greifen Sie dabei ausschließlich auf die in der Grammatik vorhandenen Lexeme zurück!\n",
    "\n",
    "\n",
    "#### (Satzzeichen müssen nicht berücksichtigt werden!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 b) Erweitern Sie die Grammatik um entsprechende syntaktische Regeln für Ihren  Satz aus 8.1a.\n",
    "\n",
    "\n",
    "- Verwenden Sie nur die bestehenden sowie ggf. `SBAR` und `COMP` als neue Nonterminale\n",
    "- X-Bar-Schema ist nicht notwendig (orientieren Sie sich an den Penn-Treebank-Regeln für komplexe Sätze)\n",
    "- Beachten Sie die invertierte Wortstellung im Nebensatz (Verbendstellung).\n",
    "\n",
    "#### Beachten Sie, dass Sie zuvor die Codezelle von 8.1a) ausgeführt haben müssen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    NP   -> PRON\n",
    "    \n",
    "    VP   -> V VP    \n",
    "    VP   -> TO V \n",
    "\n",
    "    PRON -> \"er\"\n",
    "    V    -> \"glaubt\" | \"glauben\" | \"träumt\" |\"träumen\" | \"fliegt\" | \"fliegen\"\n",
    "    TO   -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S    -> NP VP\n",
    "    NP   -> PRON\n",
    "    \n",
    "    VP   -> V VP    \n",
    "    VP   -> TO V \n",
    "\n",
    "    PRON -> \"er\"\n",
    "    V    -> \"glaubt\" | \"glauben\" | \"träumt\" |\"träumen\" | \"fliegt\" | \"fliegen\"\n",
    "    TO   -> \"zu\"\n",
    "    COMP -> \"dass\"\n",
    "    COMP ->\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8.2. Analysieren Sie die Dependenzbeziehungen Ihres Beispielsatzes aus 8.1 im UD-Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(ROOT)\n",
      "   │    \n",
      " x(dep)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a29c3473e17a4945adee1a048c1882f7-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">x</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a29c3473e17a4945adee1a048c1882f7-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a29c3473e17a4945adee1a048c1882f7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Parsing-Algorithmen und Rekursionstypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Kommentieren Sie in folgender Grammatik genau eine Regel aus, so dass der verwendete Shift-Reduce-Parser auch ohne Backtracking eine Ableitung findet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n",
      "Parsing 'sie beobachtet den Hund aus dem Versteck'\n",
      "    [ * sie beobachtet den Hund aus dem Versteck]\n",
      "  S [ 'sie' * beobachtet den Hund aus dem Versteck]\n",
      "  R [ PRON * beobachtet den Hund aus dem Versteck]\n",
      "  R [ NP * beobachtet den Hund aus dem Versteck]\n",
      "  S [ NP 'beobachtet' * den Hund aus dem Versteck]\n",
      "  R [ NP V * den Hund aus dem Versteck]\n",
      "  S [ NP V 'den' * Hund aus dem Versteck]\n",
      "  R [ NP V DET * Hund aus dem Versteck]\n",
      "  S [ NP V DET 'Hund' * aus dem Versteck]\n",
      "  R [ NP V DET N * aus dem Versteck]\n",
      "  R [ NP V NP * aus dem Versteck]\n",
      "  R [ NP VP * aus dem Versteck]\n",
      "  R [ S * aus dem Versteck]\n",
      "  S [ S 'aus' * dem Versteck]\n",
      "  R [ S P * dem Versteck]\n",
      "  S [ S P 'dem' * Versteck]\n",
      "  R [ S P DET * Versteck]\n",
      "  S [ S P DET 'Versteck' * ]\n",
      "  R [ S P DET N * ]\n",
      "  R [ S P NP * ]\n",
      "  R [ S PP * ]\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"sie beobachtet den Hund aus dem Versteck\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "\n",
    "VP -> V NP PP\n",
    "VP -> V NP\n",
    "\n",
    "NP -> DET N\n",
    "NP -> PRON\n",
    "\n",
    "PP -> P NP\n",
    "\n",
    "PRON -> \"sie\"\n",
    "V -> \"beobachtet\"\n",
    "DET -> \"den\"\n",
    "N -> \"Hund\"\n",
    "P -> \"aus\"\n",
    "DET -> \"dem\"\n",
    "N -> \"Versteck\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ShiftReduceParser(grammar,trace=2)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"sie beobachtet den Hund aus dem Versteck\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "\n",
    "VP -> V NP PP\n",
    "VP -> V NP\n",
    "\n",
    "NP -> DET N\n",
    "NP -> PRON\n",
    "\n",
    "PP -> P NP\n",
    "\n",
    "PRON -> \"sie\"\n",
    "V -> \"beobachtet\"\n",
    "DET -> \"den\"\n",
    "N -> \"Hund\"\n",
    "P -> \"aus\"\n",
    "DET -> \"dem\"\n",
    "N -> \"Versteck\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ShiftReduceParser(grammar,trace=2)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 9.2 Geben Sie zu der folgenden CFG-Regel eine weitere Regel an, die in Kombination mit dieser zu Problemen bei der Verarbeitung mit einem Recursive-Descent-Parser führt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 1 productions (start state = NP)\n",
      "    NP -> X PP\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    NP -> X PP\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    NP -> X PP\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Unifikationsparsing und getypte Merkmalstrukturen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 10.1 Unifikation und Merkmalsstrukturen\n",
    "\n",
    "#### Gegeben seien folgende (unifizierende) Merkmalsstrukturen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ X = True ]\n"
     ]
    }
   ],
   "source": [
    "f1 = FeatStruct(\"[+X]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Geben Sie eine *nicht-leere* Merkmalsstruktur `f2` an, die den boolschen Feature-Wert `False` enthält und die mit `f1`unifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "f1 = FeatStruct(\"[+X]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = FeatStruct(\"[+X]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 10.2 Unifikation mit Typen\n",
    "\n",
    "#### Gegeben sei folgende Agreement-Typhierarchie, die (mit abgekürzten Typnamen) durch das `*AGR*`-Feature implementiert wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "type_hierarchy = {\n",
    "    \"1\": [\"1sg\",\"1pl\"],\n",
    "    \"2\": [\"2sg\", \"2pl\"],\n",
    "    \"3\": [\"3sg\", \"3pl\"],\n",
    "    \"sg\": [\"1sg\", \"2sg\", \"3sg\"],\n",
    "    \"pl\": [\"1pl\", \"2pl\", \"3pl\"],\n",
    "    \"1sg\": [],\n",
    "    \"1pl\": [],\n",
    "    \"2sg\": [],\n",
    "    \"2pl\": [],\n",
    "    \"3sg\": [],\n",
    "    \"3pl\": []\n",
    "}\n",
    "AGR = HierarchicalFeature(\"AGR\", type_hierarchy)\n",
    "reader = FeatStructReader(features=(AGR,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus, um die Typhierarchie zu laden.\n",
    "\n",
    "### Geben Sie zwei *nicht-leere* Merkmalstrukturen  `f1` und `f2` an, die von `f3`verschieden sind, sodass gilt:\n",
    "\n",
    "`f1` subsumiert `f2`, `f2` subsumiert `f3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "f1 = reader.fromstring(\"[]\")\n",
    "f2 = reader.fromstring(\"[]\")\n",
    "f3 = reader.fromstring(\"[*AGR*='2sg']\")\n",
    "print(f1.subsumes(f2), f2.subsumes(f3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = reader.fromstring(\"[]\")\n",
    "f2 = reader.fromstring(\"[]\")\n",
    "f3 = reader.fromstring(\"[*AGR*='2sg']\")\n",
    "print(f1.subsumes(f2), f2.subsumes(f3)) \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Statistisches Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 11.1 PCFG: Gewichte und Ableitungswahrscheinlichkeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgende Mini-Treebank mit PP-Attachment-Sätzen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          S         \n",
      " ┌───┬────┴───┐      \n",
      " │   VP       │     \n",
      " │   │        │      \n",
      " NP  V        PP    \n",
      " │   │    ┌───┼───┐  \n",
      "Ich gehe auf dem Weg\n",
      "\n",
      "            S              \n",
      " ┌──────────┴───┐           \n",
      " │              VP         \n",
      " │    ┌─────────┴───┐       \n",
      " NP   V             PP     \n",
      " │    │     ┌───────┼───┐   \n",
      "Ich steige auf     den Berg\n",
      "\n",
      "              S              \n",
      " ┌────────────┴───┐           \n",
      " │                VP         \n",
      " │     ┌──────────┴───┐       \n",
      " NP    V              PP     \n",
      " │     │      ┌───────┼───┐   \n",
      "Ich klettere auf     den Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treestrings = [\n",
    "\"(S (NP Ich) (VP (V gehe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V steige) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V klettere) (PP auf den Berg)))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "for tree in trees:\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passen Sie diese Mini-Treebank durch Umklammern der syntaktischen Struktur einer minimalen Anzahl an Sätzen so an, dass die daraus induzierte Grammatik das S-Attachment (Satz-Adjunkt statt Subkategorisierung nach PP-Komplement) bevorzugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP PP [0.333333]\n",
      "NP -> 'Ich' [1.0]\n",
      "VP -> V [0.333333]\n",
      "V -> 'gehe' [0.333333]\n",
      "PP -> 'auf' 'dem' 'Weg' [0.333333]\n",
      "S -> NP VP [0.666667]\n",
      "VP -> V PP [0.666667]\n",
      "V -> 'steige' [0.333333]\n",
      "PP -> 'auf' 'den' 'Berg' [0.666667]\n",
      "V -> 'klettere' [0.333333]\n",
      "(S (NP Ich) (VP (V gehe) (PP auf dem Weg))) (p=0.0493827)\n",
      "          S             \n",
      " ┌────────┴───┐          \n",
      " │            VP        \n",
      " │   ┌────────┴───┐      \n",
      " NP  V            PP    \n",
      " │   │    ┌───────┼───┐  \n",
      "Ich gehe auf     dem Weg\n",
      "\n",
      "(S (NP Ich) (VP (V steige) (PP auf den Berg))) (p=0.0987654)\n",
      "            S              \n",
      " ┌──────────┴───┐           \n",
      " │              VP         \n",
      " │    ┌─────────┴───┐       \n",
      " NP   V             PP     \n",
      " │    │     ┌───────┼───┐   \n",
      "Ich steige auf     den Berg\n",
      "\n",
      "(S (NP Ich) (VP (V klettere) (PP auf den Berg))) (p=0.0987654)\n",
      "              S              \n",
      " ┌────────────┴───┐           \n",
      " │                VP         \n",
      " │     ┌──────────┴───┐       \n",
      " NP    V              PP     \n",
      " │     │      ┌───────┼───┐   \n",
      "Ich klettere auf     den Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "treestrings = [\n",
    "\"(S (NP Ich) (VP (V gehe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V steige) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V klettere) (PP auf den Berg)))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('S')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "treestrings = [\n",
    "\"(S (NP Ich) (VP (V gehe)) (PP auf dem Weg))\",\n",
    "\"(S (NP Ich) (VP (V steige) (PP auf den Berg)))\",\n",
    "\"(S (NP Ich) (VP (V klettere) (PP auf den Berg)))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('S')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11.2 Übergangsbasierter Shift-Reduce-Dependency-Parser\n",
    "\n",
    "#### Gegeben sei folgender Dependenzgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"25bda247ac4a4eabb14bbbf2b73b5c64-0\" class=\"displacy\" width=\"550\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">seltenes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">Tier</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">wurde</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">gesehen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,2.0 250.0,2.0 250.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,52.0 245.0,52.0 245.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,104.0 L162,92.0 178,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-2\" stroke-width=\"2px\" d=\"M270,102.0 C270,2.0 450.0,2.0 450.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-3\" stroke-width=\"2px\" d=\"M370,102.0 C370,52.0 445.0,52.0 445.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-25bda247ac4a4eabb14bbbf2b73b5c64-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,104.0 L362,92.0 378,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 ein 3 det \n",
    "2 seltenes 3 amod\n",
    "3 Tier 5 nsubj\n",
    "4 wurde 5 aux\n",
    "5 gesehen 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie den Typ der REDUCE-Übergänge (`LEFTARC`, `RIGHTARC`) sowie die Reihenfolge deren Durchführung bei Verarbeitung dieser Struktur mit einem Shift-Reduce-Dependency-Parser an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c21ac480d02d461488c1b4933304b714-0\" class=\"displacy\" width=\"550\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">seltenes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">Tier</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">wurde</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">gesehen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c21ac480d02d461488c1b4933304b714-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,2.0 250.0,2.0 250.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c21ac480d02d461488c1b4933304b714-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c21ac480d02d461488c1b4933304b714-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,52.0 245.0,52.0 245.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c21ac480d02d461488c1b4933304b714-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,104.0 L162,92.0 178,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c21ac480d02d461488c1b4933304b714-0-2\" stroke-width=\"2px\" d=\"M270,102.0 C270,2.0 450.0,2.0 450.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c21ac480d02d461488c1b4933304b714-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c21ac480d02d461488c1b4933304b714-0-3\" stroke-width=\"2px\" d=\"M370,102.0 C370,52.0 445.0,52.0 445.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c21ac480d02d461488c1b4933304b714-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,104.0 L362,92.0 378,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 ein 3 LEFTARC-?\n",
    "2 seltenes 3 ?\n",
    "3 Tier 5 ?\n",
    "4 wurde 5 ?\n",
    "5 gesehen 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 ein 3 LEFTARC-?\n",
    "2 seltenes 3 ?\n",
    "3 Tier 5 ?\n",
    "4 wurde 5 ?\n",
    "5 gesehen 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Datengestützte Syntaxanalyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 12.1 Lexikalisierte CFG (mit Merkmalen)\n",
    "\n",
    "\n",
    "### Führen Sie in folgender FCFG über ein HEAD-Merkmal eine vollständige Kopfannotation durch.\n",
    "\n",
    "#### Berücksichtigen Sie dabei das *Primacy-of-Content-Words* Paradigma von UD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[]\n",
      "  (NP[] (N[] er))\n",
      "  (VP[]\n",
      "    (V[] träumt)\n",
      "    (VP[]\n",
      "      (PP[] (P[] auf) (NP[] (DET[HEAD=''] den) (N[] Berg)))\n",
      "      (V[] geflogen)\n",
      "      (TO[] zu)\n",
      "      (AUX[] sein))))\n",
      "      S[]                                                  \n",
      " ┌─────┴─────┐                                              \n",
      " │          VP[]                                           \n",
      " │     ┌─────┴──────────────────────┐                       \n",
      " │     │                           VP[]                    \n",
      " │     │              ┌─────────────┴──────┬──────┬─────┐   \n",
      " │     │             PP[]                  │      │     │  \n",
      " │     │     ┌────────┴────────┐           │      │     │   \n",
      "NP[]   │     │                NP[]         │      │     │  \n",
      " │     │     │        ┌────────┴────┐      │      │     │   \n",
      "N[]   V[]   P[]  DET[HEAD='']      N[]    V[]    TO[] AUX[]\n",
      " │     │     │        │             │      │      │     │   \n",
      " er  träumt auf      den           Berg geflogen  zu   sein\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"er träumt auf den Berg geflogen zu sein\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    NP[]  -> DET[] N[]\n",
    "    NP[]  -> N[]\n",
    "    PP[]  -> P[] NP[]\n",
    "    VP[]  -> V[] VP[]\n",
    "    VP[]  -> PP[] V[] TO[] AUX[]\n",
    "\n",
    "    DET[HEAD=\"\"] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    P[]   -> \"auf\"\n",
    "    V[]   -> \"träumt\"   \n",
    "    V[]   -> \"geflogen\"    \n",
    "    AUX[] -> \"sein\"\n",
    "    TO[]  -> \"zu\"\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er träumt auf den Berg geflogen zu sein\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    NP[]  -> DET[] N[]\n",
    "    NP[]  -> N[]\n",
    "    PP[]  -> P[] NP[]\n",
    "    VP[]  -> V[] VP[]\n",
    "    VP[]  -> PP[] V[] TO[] AUX[]\n",
    "\n",
    "    DET[HEAD=\"\"] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    P[]   -> \"auf\"\n",
    "    V[]   -> \"träumt\"   \n",
    "    V[]   -> \"geflogen\"    \n",
    "    AUX[] -> \"sein\"\n",
    "    TO[]  -> \"zu\"\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 12.2 Parent Annotation (mit Symbolerweiterung)\n",
    "\n",
    "### Gegeben sei wieder obiger Satz mit entsprechender CFG.\n",
    "\n",
    "### Führen Sie über Symbolerweiterung (mit `^` als Trennerzeichen) in der CFG eine vollständige *Parent Annotation* durch, wie Sie durch die Regelanwendungen im Syntaxbaum der Angabe impliziert ist. \n",
    "\n",
    "### Ergänzen Sie ggf. auch Regeln, die für die vollständige Parent-Annotation notwendig sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      S                                      \n",
      " ┌────┴─────┐                                 \n",
      " │          VP                               \n",
      " │    ┌─────┴───────────┐                     \n",
      " │    │                 VP                   \n",
      " │    │         ┌───────┴──────┬──────┬───┐   \n",
      " │    │         PP             │      │   │  \n",
      " │    │     ┌───┴───┐          │      │   │   \n",
      " NP   │     │       NP         │      │   │  \n",
      " │    │     │   ┌───┴───┐      │      │   │   \n",
      " N    V     P  DET      N      V      TO AUX \n",
      " │    │     │   │       │      │      │   │   \n",
      " er träumt auf den     Berg geflogen  zu sein\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sentence = \"er träumt auf den Berg geflogen zu sein\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    NP  -> DET N\n",
    "    NP  -> N\n",
    "    PP  -> P NP\n",
    "    VP  -> V VP\n",
    "    VP  -> PP V TO AUX\n",
    "\n",
    "    DET -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    P   -> \"auf\"\n",
    "    V   -> \"träumt\"   \n",
    "    V   -> \"geflogen\"    \n",
    "    AUX -> \"sein\"\n",
    "    TO  -> \"zu\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er träumt auf den Berg geflogen zu sein\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    NP  -> DET N\n",
    "    NP  -> N\n",
    "    PP  -> P NP\n",
    "    VP  -> V VP\n",
    "    VP  -> PP V TO AUX\n",
    "\n",
    "    DET -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    P   -> \"auf\"\n",
    "    V   -> \"träumt\"   \n",
    "    V   -> \"geflogen\"    \n",
    "    AUX -> \"sein\"\n",
    "    TO  -> \"zu\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Chunk-Analysen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Geben Sie die *IOB-Tag-Sequenz* einer *flachen* VP-NP-Chunk-Analyse für den folgenden Satz an  (Zuordnung gemäß Gruppennummer):\n",
    "\n",
    "#### `Gruppe 1` > ***Josef Konrad ist Prokurist einer Bank***\n",
    "#### `Gruppe 2` > ***Der Wächter Franz verkündet ihm seine Verhaftung***\n",
    "#### `Gruppe 3` > ***Frau Grubach ist Josefs Vermieterin***\n",
    "\n",
    "### Schreiben Sie dazu in der unten gegebenen Liste für jedes Wort Ihres Satzes ein Tripel der Form `(WORT, POS-TAG, IOB-TAG)` (vgl. Angabe).\n",
    "\n",
    "\n",
    "#### Sie können ein beliebiges POS-Tagset verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S            \n",
      "       │             \n",
      "       NP           \n",
      "  ┌────┴──────┐      \n",
      "ein/N     Beispiel/N\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "iob_list = [\n",
    "(\"ein\", \"DET\", \"B-NP\"),\n",
    "(\"Beispiel\", \"N\", \"I-NP\"),\n",
    "]\n",
    "\n",
    "from nltk import conlltags2tree\n",
    "tree = conlltags2tree(iob_list)\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (13.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "iob_list = [\n",
    "(\"ein\", \"DET\", \"B-NP\"),\n",
    "(\"Beispiel\", \"N\", \"I-NP\"),\n",
    "]\n",
    "\n",
    "from nltk import conlltags2tree\n",
    "tree = conlltags2tree(iob_list)\n",
    "tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
