{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***'Syntax natürlicher Sprachen',*** **Wintersemester 2020/21**\n",
    "\n",
    "--- \n",
    "# Klausur: Syntax natürlicher Sprachen *(06.03.2021)*\n",
    "\n",
    "- **Bearbeitungszeitraum: 10:15-11:45**\n",
    "- **Abgabe in Moodle bis 12:05**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Übersicht\n",
    "\n",
    "- [Hinweise zur Bearbeitung](#Hinweise-zur-Bearbeitung)\n",
    "- [Laden von Paketen](#Laden-von-Paketen)\n",
    "\n",
    "\n",
    "1. [Temporale-Ambiguität](#1.-Temporale-Ambiguität)\n",
    "2. [Syntaktische Ambiguität](#2.-Syntaktische-Ambiguität)\n",
    "3. [Konstituenten- und Adjunkttests](#3.-Konstituenten--und-Adjunkttests)\n",
    "4. [CFG Analysen](#4.-CFG-Analysen)\n",
    "5. [Dependenzanalyse](#5.-Dependenzanalyse)\n",
    "6. [FCFG-Erweiterung: Kasus, Agreement, Subkategorisierung](#6.-FCFG-Erweiterung:-Kasus,-Agreement,-Subkategorisierung)\n",
    "7. [Slash-Kategorien, Inversion, Wortstellung](#7.-Slash-Kategorien,-Inversion,-Wortstellung)\n",
    "8. [Syntaxregeln komplexer Sätze](#8.-Syntaxregeln-komplexer-Sätze)\n",
    "9. [Parsing-Algorithmen und Rekursionstypen](#9.-Parsing-Algorithmen-und-Rekursionstypen)\n",
    "10. [Unifikationsparsing](#10.-Unifikationsparsing-und-getypte-Merkmalstrukturen)\n",
    "11. [Statistisches Parsing](#11.-Statistisches-Parsing)\n",
    "12. [Datengestützte Syntaxanalyse](#12.-Datengestützte-Syntaxanalyse)\n",
    "13. [Chunk-Analysen und Komplexität](#13.-Chunk-Analysen-und-Komplexität)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hinweise zur Bearbeitung\n",
    "\n",
    "### Falls noch nicht geschehen, benennen Sie bitte zunächst die Datei der Klausur-Angabe nach folgendem Schema um: \n",
    "\n",
    " #### `Nachname_Vorname_Matrikelnummer.ipynb`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Hinweise zum Ausfüllen der Codezellen\n",
    "\n",
    "### Wenn gegeben, führen Sie zunächst die mit `#RUN` markierten Codezellen zu Beginn einer Aufgabe aus (dies ist für eine erfolgreiche Bearbeitung der Aufgabe notwendig).\n",
    "\n",
    "### Verändern Sie nur die `#TO_DO`-Codezellen (nur gemäß der Angabe in der jeweiligen Aufgabe)!\n",
    "\n",
    "### Führen Sie `#TO_DO`-Codezellen nach Bearbeitung aus, um das Output ihrer Lösung zu generieren (dieses muss als Teil Ihrer Lösung mit abgespeichert werden); bei aufeinander aufbauenden Aufgaben (`a)`, `b)`usw.) ist zudem  notwendig, dass Sie Ihre Lösung aus der vorangehenden Teilaufgabe ausführen, damit diese in der folgenden zur Verfügung steht.\n",
    "\n",
    "### Angegebene Inhalte (Grammatikregeln usw.) dürfen nicht auskommentiert oder gelöscht werden, außer dies wird explizit anders erwähnt!\n",
    "\n",
    "\n",
    "### WICHTIG: Setzen Sie den Status des Notebooks ggf. auf `Trusted`, damit alle angegebenen Outputs korrekt angezeigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Zuordung durch Matrikelnummer\n",
    "### Bearbeiten Sie, falls explizit darauf hingewiesen wird, nur das Beispiel, das Ihnen gemäß der angegebenen Verteilung anhand der letzten Stelle Ihrer Matrikelnummer zugeordnet wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Laden von Paketen\n",
    "\n",
    "### Führen Sie zu Beginn folgende Codezelle aus.\n",
    "\n",
    "### Das erfolgreiche Ausführen dieser Codezelle ist Voraussetzung für die Bearbeitung der folgenden Aufgaben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk import FeatStruct\n",
    "import itertools\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "def transform_nr_conll(sent_nr):\n",
    "    sent_list = []\n",
    "    for line in list(filter(None, sent_nr.split(\"\\n\"))):\n",
    "        line_list = line.split()\n",
    "        line_list.pop(0)\n",
    "        line_list.insert(1,\"_\")\n",
    "        sent_list.append(\" \".join([i for i in line_list[0:]]))\n",
    "\n",
    "    return \"\\n\".join([i for i in sent_list[0:]])\n",
    "\n",
    "\n",
    "\n",
    "from nltk import DependencyGraph\n",
    "from itertools import chain\n",
    "\n",
    "def _tree_labeled(self, i):\n",
    "        node = self.get_by_address(i)\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]        \n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "\n",
    "        if deps:\n",
    "            return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "        else:\n",
    "            return word+'('+rel+')'\n",
    "        \n",
    "def tree_labeled(self):\n",
    "        node = self.root\n",
    "\n",
    "        word = node[\"word\"]\n",
    "        rel = node[\"rel\"]\n",
    "        deps = sorted(chain.from_iterable(node[\"deps\"].values()))\n",
    "        return Tree(word+'('+rel+')', [self._tree_labeled(dep) for dep in deps])\n",
    "\n",
    "DependencyGraph._tree_labeled = _tree_labeled\n",
    "DependencyGraph.tree_labeled = tree_labeled\n",
    "\n",
    "\n",
    "\n",
    "def displacy_dep_input(sent):\n",
    "    deps = []\n",
    "    for dep in sent.split('\\n'):\n",
    "        deps.append(dep.split())\n",
    "\n",
    "    deps = [x for x in deps if x]\n",
    "\n",
    "    ex = []\n",
    "    word_list = []\n",
    "    arc_list = []\n",
    "\n",
    "    for index, dep in enumerate(deps):\n",
    "        word_list.append({\"text\": dep[0], \"tag\": \"\"})\n",
    "        line = index+1\n",
    "        head = int(dep[2])\n",
    "        label = dep[3]\n",
    "        if head>line:\n",
    "            start = index\n",
    "            end = head-1\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            start = head-1\n",
    "            end = index  \n",
    "            direction = \"right\"\n",
    "        if(label.lower() != \"root\"):\n",
    "            arc_list.append({\"start\": start, \"end\": end, \"label\": label, \"dir\": direction})\n",
    "\n",
    "    ex.append({\n",
    "        \"words\": word_list,\n",
    "        \"arcs\": arc_list\n",
    "    })    \n",
    "\n",
    "    return ex\n",
    "\n",
    "\n",
    "\n",
    "from nltk.featstruct import Feature, UnificationFailure, FeatStructReader\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_sanity_constraints(th):\n",
    "    for type1, type2 in itertools.product(th, th):\n",
    "        if type1 in th[type2] and type2 in th[type1]:\n",
    "            if type1 != type2:\n",
    "                raise ValueError(\n",
    "                    \"The type hierarchy is not antisymmetric! \" +\n",
    "                    \"{} subsumes {} and vice versa!\".format(\n",
    "                        type1, type2\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "def refl_trans_closure(type_hierarchy):\n",
    "    # make everything a set\n",
    "    # and compute reflexive closure\n",
    "    closure = defaultdict(set)\n",
    "    for t in type_hierarchy:\n",
    "        closure[t] = set(type_hierarchy[t])\n",
    "        closure[t].add(t)\n",
    "\n",
    "    # compute transitive closure\n",
    "    still_changes = True\n",
    "    while still_changes:\n",
    "        still_changes = False\n",
    "        for x in closure:\n",
    "            new_for_x = set()\n",
    "            for y in closure[x]:\n",
    "                for z in closure[y]:\n",
    "                    new_for_x.add(z)\n",
    "            len_before = len(closure[x])\n",
    "            closure[x].update(new_for_x)\n",
    "            still_changes |= len(closure[x]) > len_before\n",
    "\n",
    "    return closure\n",
    "\n",
    "\n",
    "class HierarchicalFeature(Feature):\n",
    "    def __init__(self, name, type_hierarchy, **kwargs):\n",
    "        super(HierarchicalFeature, self).__init__(name, **kwargs)\n",
    "\n",
    "        self.hierarchy = refl_trans_closure(type_hierarchy)\n",
    "        check_sanity_constraints(self.hierarchy)\n",
    "\n",
    "    def unify_base_values(self, fval1, fval2, bindings):\n",
    "        candidates = self.hierarchy[fval1].intersection(self.hierarchy[fval2])\n",
    "        score = {t: 0 for t in candidates}\n",
    "        for type1, type2 in itertools.product(candidates, candidates):\n",
    "            if type1 in self.hierarchy[type2]:\n",
    "                score[type1] += 1\n",
    "\n",
    "        return min(candidates, key=score.__getitem__, default=UnificationFailure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[zurück zur Übersicht](#Übersicht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Temporale Ambiguität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wählen Sie unten zunächst den Ihnen (gemäß der letzten Stelle Ihrer Matrikelnummer) zugewiesenen Beispielsatz aus, indem Sie diesen in der folgenden Zelle einkommentieren:\n",
    "\n",
    "- `Mnr 0-5:` ***Max begegnet die Katze***  \n",
    "    - `intendierte Struktur:` *(Max begegnet)VP die Katze* \n",
    "\n",
    "\n",
    "- `Mnr 6-9:` ***the horce raced past the barn fell***\n",
    "    - `intendierte Struktur:` *the horce raced past the barn (fell)VP*\n",
    "\n",
    "\n",
    "### Schreiben Sie zu diesem *Beispielsatz für temporale syntaktische Ambiguität*  eine minimale CFG, die die intendierte Struktur des Satzes erkennt. \n",
    "\n",
    "### Testen Sie anschließend Ihre Grammatik (nur die korrekte Analyse wird ausgegeben).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S               \n",
      "     ┌────────────┴───────┐        \n",
      "     VP                   │       \n",
      " ┌───┴─────┐              │        \n",
      " NP        │              NP      \n",
      " │         │          ┌───┴────┐   \n",
      " N         V         Det       N  \n",
      " │         │          │        │   \n",
      "Max     begegnet     die     Katze\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "\n",
    "#sentence = \"Max begegnet die Katze\"\n",
    "#sentence = \"the horce raced past the barn fell\"\n",
    "\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (1):*\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "#sentence = \"Max begegnet die Katze\"\n",
    "#sentence = \"the horce raced past the barn fell\"\n",
    "\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Syntaktische Ambiguität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wählen Sie unten zunächst das Ihnen (gemäß der letzten Stelle Ihrer Matrikelnummer) zugewiesene Beispiel aus, indem Sie es in der folgenden Zelle einkommentieren:\n",
    "\n",
    "- `Mnr 0-5:` ***visiting relatives can be tiresome***\n",
    "\n",
    "\n",
    "- `Mnr 6-9:` ***Alte und Junge aus München***\n",
    "\n",
    "\n",
    "### Schreiben Sie zu diesem Beispiel für syntaktische Ambiguität eine (ungelabelte) Dependenzgrammatik. Verwenden Sie dabei die TIGER-Dependenzregeln.\n",
    "\n",
    "\n",
    "### Testen Sie anschließend Ihre Grammatik (Ausgabe von mindestens zwei grammatisch korrekten Analysen).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(can visiting relatives (be tiresome)) \n",
      "\n",
      "            can            \n",
      "   ┌─────────┼────────┐     \n",
      "   │         │        be   \n",
      "   │         │        │     \n",
      "visiting relatives tiresome\n",
      "\n",
      "(can (visiting relatives) (be tiresome)) \n",
      "\n",
      "          can         \n",
      "    ┌──────┴─────┐     \n",
      " visiting        be   \n",
      "    │            │     \n",
      "relatives     tiresome\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "\n",
    "#sentence = \"visiting relatives can be tiresome\"\n",
    "#sentence = \"Alte und Junge aus München\"\n",
    "\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "#sentence = \"visiting relatives can be tiresome\"\n",
    "#sentence = \"Alte und Junge aus München\"\n",
    "\n",
    "\n",
    "grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ProjectiveDependencyParser(grammar)\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree, \"\\n\")\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 3. Konstituenten- und Adjunkttests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Permutationstest \n",
    "\n",
    "#### Gegeben sei folgender Satz sowie die Permutationen seiner vier Satzglieder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('der Kassierer', 'gibt', 'ihr', 'einen Euro')\n",
      "1 ('der Kassierer', 'gibt', 'einen Euro', 'ihr')\n",
      "2 ('der Kassierer', 'ihr', 'gibt', 'einen Euro')\n",
      "3 ('der Kassierer', 'ihr', 'einen Euro', 'gibt')\n",
      "4 ('der Kassierer', 'einen Euro', 'gibt', 'ihr')\n",
      "5 ('der Kassierer', 'einen Euro', 'ihr', 'gibt')\n",
      "6 ('gibt', 'der Kassierer', 'ihr', 'einen Euro')\n",
      "7 ('gibt', 'der Kassierer', 'einen Euro', 'ihr')\n",
      "8 ('gibt', 'ihr', 'der Kassierer', 'einen Euro')\n",
      "9 ('gibt', 'ihr', 'einen Euro', 'der Kassierer')\n",
      "10 ('gibt', 'einen Euro', 'der Kassierer', 'ihr')\n",
      "11 ('gibt', 'einen Euro', 'ihr', 'der Kassierer')\n",
      "12 ('ihr', 'der Kassierer', 'gibt', 'einen Euro')\n",
      "13 ('ihr', 'der Kassierer', 'einen Euro', 'gibt')\n",
      "14 ('ihr', 'gibt', 'der Kassierer', 'einen Euro')\n",
      "15 ('ihr', 'gibt', 'einen Euro', 'der Kassierer')\n",
      "16 ('ihr', 'einen Euro', 'der Kassierer', 'gibt')\n",
      "17 ('ihr', 'einen Euro', 'gibt', 'der Kassierer')\n",
      "18 ('einen Euro', 'der Kassierer', 'gibt', 'ihr')\n",
      "19 ('einen Euro', 'der Kassierer', 'ihr', 'gibt')\n",
      "20 ('einen Euro', 'gibt', 'der Kassierer', 'ihr')\n",
      "21 ('einen Euro', 'gibt', 'ihr', 'der Kassierer')\n",
      "22 ('einen Euro', 'ihr', 'der Kassierer', 'gibt')\n",
      "23 ('einen Euro', 'ihr', 'gibt', 'der Kassierer')\n"
     ]
    }
   ],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "sentence = [\"der Kassierer\", \"gibt\", \"ihr\", \"einen Euro\"]\n",
    "\n",
    "permutations = list(itertools.permutations(sentence))\n",
    "for (i, item) in enumerate(permutations):\n",
    "    print(i, item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus.\n",
    "\n",
    "### Geben Sie (über den Listenindex) eine Permutation des Satzes an, welche das indirekte Objekt als Konstituente bestätigt.\n",
    "\n",
    "#### (Beachten Sie dabei insbesondere die Stellungsregeln des Deutschen für Pronomen im Mittelfeld.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ihr', 'gibt', 'der Kassierer', 'einen Euro')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "list(itertools.permutations(sentence))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "list(itertools.permutations(sentence))[0]\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 3.2 Adjunkttest\n",
    "\n",
    "\n",
    "#### Gegeben sei folgender Satz, dessen drittes Satzglied den Averbialsatz-Test besteht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sie kletterte, während sie im Kletterpark war'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"sie\", \"kletterte\", \"im Kletterpark\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] + \", während sie \" + sentence[2] + \" war\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie (unter Erhalt der Wohlgeformtheit des Ausgangssatzes) ein alternatives drittes Satzglied an (an Stelle des TODO), so dass der Averbialsatz-Test fehlschlägt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sie kletterte, während sie zur Schule war'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = [\"sie\", \"kletterte\", \"TODO\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] + \", während sie \" + sentence[2] + \" war\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (3.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = [\"sie\", \"kletterte\", \"TODO\"]\n",
    "\n",
    "sentence[0] + \" \" + sentence[1] + \", während sie \" + sentence[2] + \" war\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. CFG-Analysen\n",
    "\n",
    "#### Gegeben sei folgender Satz und eine entsprechende Grammatik:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S          \n",
      "     ┌───────┴───────┐   \n",
      "     NP              VP \n",
      " ┌───┴───────┐       │   \n",
      "Det          N       V  \n",
      " │           │       │   \n",
      "der     Briefträger geht\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Briefträger geht\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"geht\"    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Passen Sie den Satz der Angabe an, so dass er ein \n",
    "\n",
    "- `Mnr 0-3:` **Kasusadverbial**\n",
    "\n",
    "\n",
    "- `Mnr 4-6:` **adverbiales Komplement**\n",
    "\n",
    "\n",
    "- `Mnr 7-9:` **Präpositionalobjekt**\n",
    "\n",
    "### enthält (Zuordnung gemäß Matrikelnummer).\n",
    "\n",
    "### Verwenden Sie dabei das der jeweiligen Konstruktion entsprechende Verb aus folgender Liste:\n",
    "\n",
    "- *steigt (auf/in)*\n",
    "- *schläft*\n",
    "- *wartet (auf)* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"der Briefträger TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Erweitern Sie die Grammatik um entsprechende lexikalische und syntaktische Regeln für den erweiterten Satz.  Halten Sie sich dabei in den ergänzten Regeln an das X-Bar-Schema!\n",
    "\n",
    "#### Verwenden Sie `VERBAL` als Symbol für `V'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       S                          \n",
      "     ┌─────────────────┴─────────┐                 \n",
      "     │                           VP               \n",
      "     │                 ┌─────────┴────┐            \n",
      "     │                 │              NP          \n",
      "     │                 │     ┌────────┴─────┐      \n",
      "     NP                │     │             Nom    \n",
      " ┌───┴───────┐         │     │        ┌─────┴───┐  \n",
      "Det          N         V    Det      ADJ        N \n",
      " │           │         │     │        │         │  \n",
      "der     Briefträger schläft den     ganzen     Tag\n",
      "\n",
      "                       S                          \n",
      "     ┌─────────────────┴─────────┐                 \n",
      "     │                           VP               \n",
      "     │                 ┌─────────┴────┐            \n",
      "     NP                │              NP          \n",
      " ┌───┴───────┐         │     ┌────────┴─────┐      \n",
      " │          Nom        │     │             Nom    \n",
      " │           │         │     │        ┌─────┴───┐  \n",
      "Det          N         V    Det      ADJ        N \n",
      " │           │         │     │        │         │  \n",
      "der     Briefträger schläft den     ganzen     Tag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"geht\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"der Briefträger TODO\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (4b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "\n",
    "    Det -> \"der\"\n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"geht\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Dependenzanalyse\n",
    "\n",
    "### Analysieren Sie die Dependenzbeziehungen Ihres Beispielsatzes aus der Aufgabe 4a) im UD-Schema. Verwenden Sie das aus der Vorlesung bekannte Format: \n",
    "\n",
    "- pro Zeile: `Position, Wort, Position des Kopfes, Dependenzrelation`\n",
    "- Wurzelknoten: `Position des Kopfes` = 0, `Dependenzrelation` = ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             schläft(ROOT)                      \n",
      "     ┌─────────────┴──────────┐                  \n",
      "Briefträger(               Tag(obl)             \n",
      "   nsubj)                     │                 \n",
      "     │             ┌──────────┴──────────┐       \n",
      "  Der(det)      den(det)            ganzen(amod)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1627dcb5b5e34eb4971d771d37ec0773-0\" class=\"displacy\" width=\"650\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Der</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">Briefträger</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">schläft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">den</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">ganzen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">Tag</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1627dcb5b5e34eb4971d771d37ec0773-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,102.0 140.0,102.0 140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1627dcb5b5e34eb4971d771d37ec0773-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1627dcb5b5e34eb4971d771d37ec0773-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,102.0 240.0,102.0 240.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1627dcb5b5e34eb4971d771d37ec0773-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1627dcb5b5e34eb4971d771d37ec0773-0-2\" stroke-width=\"2px\" d=\"M370,152.0 C370,52.0 545.0,52.0 545.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1627dcb5b5e34eb4971d771d37ec0773-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1627dcb5b5e34eb4971d771d37ec0773-0-3\" stroke-width=\"2px\" d=\"M470,152.0 C470,102.0 540.0,102.0 540.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1627dcb5b5e34eb4971d771d37ec0773-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,154.0 L462,142.0 478,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1627dcb5b5e34eb4971d771d37ec0773-0-4\" stroke-width=\"2px\" d=\"M270,152.0 C270,2.0 550.0,2.0 550.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1627dcb5b5e34eb4971d771d37ec0773-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,154.0 L558.0,142.0 542.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (5):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. FCFG-Erweiterung: Kasus, Agreement, Subkategorisierung\n",
    "\n",
    "#### Gegeben sei folgende Grammatik mit VP-Regeln für transitive sowie intransitive Verben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron    \n",
    "\n",
    "    Pron -> \"ich\"\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"   \n",
    "    N   -> \"Hund\" \n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\" \n",
    "    V   -> \"rennt\" \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Grammatik erkennt u.a. folgende, grammatisch korrekte Sätze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         S        \n",
      "     ┌───┴─────┐   \n",
      "     NP        VP \n",
      " ┌───┴───┐     │   \n",
      "Det      N     V  \n",
      " │       │     │   \n",
      "der     Hund rennt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund rennt\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              S                      \n",
      "     ┌────────┴────┐                  \n",
      "     │             VP                \n",
      "     │        ┌────┴───┐              \n",
      "     NP       │        NP            \n",
      " ┌───┴───┐    │    ┌───┴───────┐      \n",
      "Det      N    V   Det          N     \n",
      " │       │    │    │           │      \n",
      "der     Hund jagt den     Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"der Hund jagt den Briefträger\"\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Geben Sie einen nach den Regeln der deutschen Grammatik nicht-wohlgeformten Satz an, der fälschlicherweise von der oben angegebenen Grammatik erkannt wird, obwohl er gegen das folgende Constraint verstößt (Zuordnung gemäß Matrikelnummer): \n",
    "\n",
    "\n",
    "- `Mnr 0-2:` **Subkategorisierung**\n",
    "\n",
    "\n",
    "- `Mnr 3-4:` **Subjekt-Kasus**\n",
    "\n",
    "\n",
    "- `Mnr 5-7:` **Objekt-Kasus**\n",
    "\n",
    "\n",
    "- `Mnr 8-9:` **Subjekt-Verb-Agreement**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S               \n",
      "     ┌─────────┴────┐           \n",
      "     │              VP         \n",
      "     │         ┌────┴───┐       \n",
      "     NP        │        NP     \n",
      " ┌───┴───┐     │    ┌───┴───┐   \n",
      "Det      N     V   Det      N  \n",
      " │       │     │    │       │   \n",
      "der     Hund rennt den     Hund\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "neg_sentence = \"\"\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b) Erweitern Sie die angegebene Grammatik um die notwendigen Merkmale, um die Überproduktion aus 6a) zu verhindern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron    \n",
    "\n",
    "    Pron -> \"ich\"\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"   \n",
    "    N   -> \"Hund\" \n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\" \n",
    "    V   -> \"rennt\"   \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=1)\n",
    "\n",
    "#NEGATIVBEISPIEL (neg_sentence aus 6a):\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "neg_sentence = \"\"\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (6b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    VP  -> V\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron    \n",
    "\n",
    "    Pron -> \"ich\"\n",
    "    Det -> \"der\"\n",
    "    Det -> \"den\"   \n",
    "    N   -> \"Hund\" \n",
    "    N   -> \"Briefträger\"\n",
    "    V   -> \"jagt\" \n",
    "    V   -> \"rennt\"   \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=1)\n",
    "\n",
    "#NEGATIVBEISPIEL (neg_sentence aus 6a):\n",
    "for tree in parser.parse(neg_sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Slash-Kategorien, Inversion, Wortstellung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgender Satz und eine FCFG, die - ausgehend von der Annahme einer OV-Grundworstellung in der VP (\"wen gesehen haben\") - die Subjekt-VP-Inversion für den Fragesatz sowie das Herausbewegen des Vollverbs aus der VP über eine Slash-Kategorie modelliert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S[]', [Tree('VP[]/V[]', [Tree('NP[]', [Tree('QPron[]', ['wen'])]), Tree('V[]/V[]', []), Tree('Aux[]', ['hat'])]), Tree('NP[]', [Tree('Pron[]', ['sie'])]), Tree('V[]', ['gesehen'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"wen hat sie gesehen\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "\n",
    "    S -> VP/V NP V\n",
    "\n",
    "    VP/?x -> NP V/?x Aux\n",
    "\n",
    "    V/V -> \n",
    "\n",
    "    NP -> Pron | QPron\n",
    "\n",
    "    QPron   -> \"wen\"\n",
    "    Pron   -> \"sie\"\n",
    "    Aux   -> \"hat\" \n",
    "    V   -> \"gesehen\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    #tree.pretty_print(unicodelines=True)\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie die Regel aus obenstehender Grammatik an, die das folgende implementiert (Zuordnung gemäß Matrikelnummer):\n",
    "\n",
    "\n",
    "\n",
    "- `Mnr 0-2:` **`SUBJEKT-VP-INVERSION`**\n",
    "\n",
    "\n",
    "- `Mnr 3-4:` **`GAP-INTRODUCTION`**\n",
    "\n",
    "\n",
    "- `Mnr 5-7:` **`HERUNTERREICHEN DER GAP-INFORMATIONEN`**\n",
    "\n",
    "\n",
    "- `Mnr 8-9:` **`GAP-REALISIERUNG`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (7):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "gramstring = r\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Syntaxregeln komplexer Sätze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 CFG-Regeln für komplexe Sätze\n",
    "\n",
    "#### Gegeben sei folgender Satz mit transitivem Verb und eine entsprechende Grammatik:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                S                     \n",
      " ┌──────────────┴───┐                  \n",
      " │                  VP                \n",
      " │       ┌──────────┴───┐              \n",
      " NP      │              NP            \n",
      " │       │          ┌───┴───────┐      \n",
      "Pron     V         Det          N     \n",
      " │       │          │           │      \n",
      " es  erheitert     den     Briefträger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"es erheitert den Briefträger\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"Briefträger\"\n",
    "    Pron   -> \"es\"\n",
    "    V   -> \"erheitert\"\n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 a) Passen Sie den Satz  in der folgenden Zelle an, so dass er einen:\n",
    "\n",
    "- `Mnr 0-3:` **Subjektsatz**\n",
    "\n",
    "\n",
    "- `Mnr 4-6:` **Adverbialsatz**\n",
    "\n",
    "\n",
    "- `Mnr 7-9:` **Relativsatz**\n",
    "\n",
    "### enthält (Zuordnung gemäß Matrikelnummer).\n",
    "\n",
    "### Dieser Nebensatz soll dabei folgende VP enthalten:  \n",
    "\n",
    " *einen Brief schreiben*\n",
    "\n",
    "\n",
    "\n",
    "#### (Satzzeichen müssen nicht berücksichtigt werden!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "sentence = \"es erheitert den Briefträger\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 b) Erweitern Sie die Grammatik um entsprechende lexikalische und syntaktische Regeln für Ihren  Satz aus 8.1a.\n",
    "\n",
    "\n",
    "\n",
    "- Verwenden Sie nur `SBAR` und `Comp` als neue Nonterminale\n",
    "- X-Bar-Schema ist nicht notwendig (orientieren Sie sich an den Penn-Treebank-Regeln für komplexe Sätze)\n",
    "\n",
    "##### Beachten Sie die invertierte Wortstellung im Nebensatz (Verbendstellung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"Briefträger\"\n",
    "    Pron   -> \"es\"\n",
    "    V   -> \"erheitert\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1a):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"es erheitert den Briefträger\"\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.1b):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V NP\n",
    "    NP  -> Det N\n",
    "    NP  -> Pron\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"Briefträger\"\n",
    "    Pron   -> \"es\"\n",
    "    V   -> \"erheitert\"\n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8.2. Analysieren Sie die Dependenzbeziehungen Ihres Beispielsatzes aus 8.1 im UD-Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(ROOT)\n",
      "   │    \n",
      " x(dep)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4c2793c6978d432cbbf4f035a0837c53-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">x</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4c2793c6978d432cbbf4f035a0837c53-0-0\" stroke-width=\"2px\" d=\"M70,52.0 C70,2.0 150.0,2.0 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4c2793c6978d432cbbf4f035a0837c53-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,54.0 L62,42.0 78,42.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (8.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 x 2 dep\n",
    "2 y 0 ROOT\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "tree_labeled = dg.tree_labeled()\n",
    "tree_labeled.pretty_print(unicodelines=True)  \n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Parsing-Algorithmen und Rekursionstypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Geben Sie CFG-Regeln an, die bei einem Bottom-Up-Parser wegen Ambiguität zu längerer Laufzeit führen können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 9.2 Geben Sie eine CFG-Regel an, die nicht mit einem Recursive-Descent-Parser verarbeitet werden kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 1 productions (start state = VP)\n",
      "    VP -> VP PP\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (9.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(grammar)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Unifikationsparsing und getypte Merkmalstrukturen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 10.1 Unifikation und Merkmalsstrukturen\n",
    "\n",
    "#### Gegeben seien folgende (unifizierende) Merkmalsstrukturen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ CAT = [ FEAT = True ] ]\n"
     ]
    }
   ],
   "source": [
    "f1 = FeatStruct(\"[CAT=[+FEAT]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Geben Sie eine Merkmalsstruktur `f2` an, die ***nicht*** mit `f1`unifiziert (print-Ausgabe: None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "f1 = FeatStruct(\"[CAT=[+FEAT]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = FeatStruct(\"[CAT=[+FEAT]]\")\n",
    "f2 = FeatStruct(\"[]\")\n",
    "print(f1.unify(f2))\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 10.2 Unifikation mit Typen\n",
    "\n",
    "#### Gegeben sei folgende Typhierarchie:\n",
    "\n",
    "$$\\bot \\sqsubseteq \\text{Genitiv}$$\n",
    "$$\\bot \\sqsubseteq \\text{nicht-Genitiv}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Nominativ-Akkusativ}$$\n",
    "$$\\text{nicht-Genitiv} \\sqsubseteq \\text{Dativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Nominativ}$$\n",
    "$$\\text{Nominativ-Akkusativ} \\sqsubseteq \\text{Akkusativ}$$\n",
    "\n",
    "####  Sie wird (mit abgekürzten Typnamen) durch das `*CASE*`-Feature implementiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN (Führen Sie zunächst diese Code-Zelle aus):\n",
    "type_hierarchy = {\n",
    "    \"nichtGen\": [\"NomAkk\", \"Dat\"],\n",
    "    \"NomAkk\": [\"Nom\", \"Akk\"],\n",
    "    \"Dat\": [],\n",
    "    \"Akk\": [],\n",
    "    \"Gen\": [],\n",
    "    \"Nom\": []\n",
    "}\n",
    "CASE = HierarchicalFeature(\"CASE\", type_hierarchy)\n",
    "reader = FeatStructReader(features=(CASE,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie obenstehende Codezelle aus, um die Typhierarchie zu laden.\n",
    "\n",
    "### Geben Sie eine Merkmalstruktur `f3` an, sodass gilt:\n",
    "\n",
    "`f1` subsumiert `f3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "f1 = reader.fromstring(\"[*CASE*=NomAkk]\")\n",
    "f3 = reader.fromstring(\"[]\")\n",
    "f1.subsumes(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (10.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "f1 = reader.fromstring(\"[*CASE*=NomAkk]\")\n",
    "f3 = reader.fromstring(\"[]\")\n",
    "f1.subsumes(f3)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Statistisches Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 11.1 PCFG: Gewichte und Ableitungswahrscheinlichkeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Gegeben sei folgende Mini-Treebank mit PP-Attachment-Sätzen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S                               \n",
      " ┌───┴─────────────┐                  \n",
      " │                 VP                \n",
      " │        ┌────────┴─────────┐        \n",
      " │        VP                 │       \n",
      " │   ┌────┴───┐              │        \n",
      " NP  V        NP             PP      \n",
      " │   │    ┌───┴────┐     ┌───┼────┐   \n",
      " Er legt die     Karten auf den Tisch\n",
      "\n",
      "     S                               \n",
      " ┌───┴─────────────┐                  \n",
      " │                 VP                \n",
      " │   ┌─────────────┴─────┐            \n",
      " │   │                   NP          \n",
      " │   │        ┌──────────┴───┐        \n",
      " NP  V        NP             PP      \n",
      " │   │    ┌───┴────┐     ┌───┼────┐   \n",
      " Er legt die     Karten auf dem Tisch\n",
      "\n",
      "            S                              \n",
      " ┌──────────┴───────┐                       \n",
      " │                  VP                     \n",
      " │          ┌───────┴────────┐              \n",
      " │          VP               │             \n",
      " │    ┌─────┴───┐            │              \n",
      " NP   V         NP           PP            \n",
      " │    │     ┌───┴───┐    ┌───┴───────┐      \n",
      "Wir trafen das     Tier  im     Schlafanzug\n",
      "\n",
      "            S                                  \n",
      " ┌──────────┴───────┐                           \n",
      " │                  VP                         \n",
      " │    ┌─────────────┴────┐                      \n",
      " │    │                  NP                    \n",
      " │    │         ┌────────┴───────┐              \n",
      " NP   V         NP               PP            \n",
      " │    │     ┌───┴───┐        ┌───┴───────┐      \n",
      "Wir trafen das     Tier      im     Schlafanzug\n",
      "\n",
      "      S                                \n",
      " ┌────┴────────────┐                    \n",
      " │                 VP                  \n",
      " │    ┌────────────┴────┐               \n",
      " │    │                 NP             \n",
      " │    │        ┌────────┴───┐           \n",
      " NP   V        NP           PP         \n",
      " │    │    ┌───┴───┐    ┌───┼─────┐     \n",
      "Sie kennt das     Tier mit dem Fernglas\n",
      "\n",
      "      S                                \n",
      " ┌────┴────────────┐                    \n",
      " │                 VP                  \n",
      " │    ┌────────────┴────┐               \n",
      " │    │                 NP             \n",
      " │    │        ┌────────┴───┐           \n",
      " NP   V        NP           PP         \n",
      " │    │    ┌───┴───┐    ┌───┼─────┐     \n",
      "Sie mögen das     Tier mit dem Fernglas\n",
      "\n",
      "      S                                \n",
      " ┌────┴────────────┐                    \n",
      " │                 VP                  \n",
      " │    ┌────────────┴────┐               \n",
      " │    │                 NP             \n",
      " │    │        ┌────────┴───┐           \n",
      " NP   V        NP           PP         \n",
      " │    │    ┌───┴───┐    ┌───┼─────┐     \n",
      "Wir sehen das     Tier mit dem Fernglas\n",
      "\n",
      "             S                        \n",
      " ┌───────────┴───┐                     \n",
      " │               VP                   \n",
      " │     ┌─────────┴───┐                 \n",
      " NP    V             PP               \n",
      " │     │     ┌───────┼────────┐        \n",
      " Du glaubst  an     den Weihnachtsmann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treestrings = [\n",
    "\"(S (NP Er) (VP (VP (V legt) (NP die Karten)) (PP auf den Tisch)))\",\n",
    "\"(S (NP Er) (VP (V legt) (NP (NP die Karten) (PP auf dem Tisch))))\",\n",
    "\"(S (NP Wir) (VP (VP (V trafen) (NP das Tier)) (PP im Schlafanzug)))\",\n",
    "\"(S (NP Wir) (VP (V trafen) (NP (NP das Tier) (PP im Schlafanzug))))\",\n",
    "\"(S (NP Sie) (VP (V kennt) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Sie) (VP (V mögen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Wir) (VP (V sehen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Du) (VP (V glaubst) (PP an den Weihnachtsmann)))\",\n",
    "]\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "for tree in trees:\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passen Sie diese Mini-Treebank durch Auskommentieren einer minimalen Anzahl an Sätzen so an, dass die daraus induzierte Grammatik das VP-Attachment bevorzugt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP [1.0]\n",
      "NP -> 'Er' [0.142857]\n",
      "VP -> VP PP [0.25]\n",
      "VP -> V NP [0.625]\n",
      "V -> 'legt' [0.333333]\n",
      "NP -> 'die' 'Karten' [0.142857]\n",
      "PP -> 'auf' 'den' 'Tisch' [0.166667]\n",
      "NP -> NP PP [0.214286]\n",
      "PP -> 'auf' 'dem' 'Tisch' [0.166667]\n",
      "NP -> 'Wir' [0.142857]\n",
      "V -> 'trafen' [0.166667]\n",
      "NP -> 'das' 'Tier' [0.214286]\n",
      "PP -> 'im' 'Schlafanzug' [0.166667]\n",
      "NP -> 'Sie' [0.0714286]\n",
      "V -> 'mögen' [0.166667]\n",
      "PP -> 'mit' 'dem' 'Fernglas' [0.333333]\n",
      "V -> 'sehen' [0.166667]\n",
      "NP -> 'Du' [0.0714286]\n",
      "VP -> V PP [0.125]\n",
      "V -> 'glaubst' [0.166667]\n",
      "PP -> 'an' 'den' 'Weihnachtsmann' [0.166667]\n",
      "(S\n",
      "  (NP Er)\n",
      "  (VP (VP (V legt) (NP die Karten)) (PP auf den Tisch))) (p=0.000177154)\n",
      "     S                               \n",
      " ┌───┴─────────────┐                  \n",
      " │                 VP                \n",
      " │        ┌────────┴─────────┐        \n",
      " │        VP                 │       \n",
      " │   ┌────┴───┐              │        \n",
      " NP  V        NP             PP      \n",
      " │   │    ┌───┴────┐     ┌───┼────┐   \n",
      " Er legt die     Karten auf den Tisch\n",
      "\n",
      "(S\n",
      "  (NP Er)\n",
      "  (VP (VP (V legt) (NP die Karten)) (PP auf dem Tisch))) (p=0.000177154)\n",
      "     S                               \n",
      " ┌───┴─────────────┐                  \n",
      " │                 VP                \n",
      " │        ┌────────┴─────────┐        \n",
      " │        VP                 │       \n",
      " │   ┌────┴───┐              │        \n",
      " NP  V        NP             PP      \n",
      " │   │    ┌───┴────┐     ┌───┼────┐   \n",
      " Er legt die     Karten auf dem Tisch\n",
      "\n",
      "(S\n",
      "  (NP Wir)\n",
      "  (VP (VP (V trafen) (NP das Tier)) (PP im Schlafanzug))) (p=0.000132866)\n",
      "            S                              \n",
      " ┌──────────┴───────┐                       \n",
      " │                  VP                     \n",
      " │          ┌───────┴────────┐              \n",
      " │          VP               │             \n",
      " │    ┌─────┴───┐            │              \n",
      " NP   V         NP           PP            \n",
      " │    │     ┌───┴───┐    ┌───┴───────┐      \n",
      "Wir trafen das     Tier  im     Schlafanzug\n",
      "\n",
      "(S\n",
      "  (NP Sie)\n",
      "  (VP (VP (V mögen) (NP das Tier)) (PP mit dem Fernglas))) (p=0.000132866)\n",
      "      S                                \n",
      " ┌────┴────────────┐                    \n",
      " │                 VP                  \n",
      " │         ┌───────┴────────┐           \n",
      " │         VP               │          \n",
      " │    ┌────┴───┐            │           \n",
      " NP   V        NP           PP         \n",
      " │    │    ┌───┴───┐    ┌───┼─────┐     \n",
      "Sie mögen das     Tier mit dem Fernglas\n",
      "\n",
      "(S\n",
      "  (NP Wir)\n",
      "  (VP (VP (V sehen) (NP das Tier)) (PP mit dem Fernglas))) (p=0.000265731)\n",
      "      S                                \n",
      " ┌────┴────────────┐                    \n",
      " │                 VP                  \n",
      " │         ┌───────┴────────┐           \n",
      " │         VP               │          \n",
      " │    ┌────┴───┐            │           \n",
      " NP   V        NP           PP         \n",
      " │    │    ┌───┴───┐    ┌───┼─────┐     \n",
      "Wir sehen das     Tier mit dem Fernglas\n",
      "\n",
      "(S (NP Du) (VP (V glaubst) (PP an den Weihnachtsmann))) (p=0.000248016)\n",
      "             S                        \n",
      " ┌───────────┴───┐                     \n",
      " │               VP                   \n",
      " │     ┌─────────┴───┐                 \n",
      " NP    V             PP               \n",
      " │     │     ┌───────┼────────┐        \n",
      " Du glaubst  an     den Weihnachtsmann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "treestrings = [\n",
    "\"(S (NP Er) (VP (VP (V legt) (NP die Karten)) (PP auf den Tisch)))\",\n",
    "\"(S (NP Er) (VP (V legt) (NP (NP die Karten) (PP auf dem Tisch))))\",\n",
    "\"(S (NP Wir) (VP (VP (V trafen) (NP das Tier)) (PP im Schlafanzug)))\",\n",
    "\"(S (NP Wir) (VP (V trafen) (NP (NP das Tier) (PP im Schlafanzug))))\",\n",
    "\"(S (NP Sie) (VP (V kennt) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Sie) (VP (V mögen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Wir) (VP (V sehen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Du) (VP (V glaubst) (PP an den Weihnachtsmann)))\",\n",
    "]\n",
    "\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "\n",
    "#grammar induction:\n",
    "productions = []\n",
    "S = nltk.Nonterminal('S')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "\n",
    "#parse trees with grammar:\n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "\n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "treestrings = [\n",
    "\"(S (NP Er) (VP (VP (V legt) (NP die Karten)) (PP auf den Tisch)))\",\n",
    "\"(S (NP Er) (VP (V legt) (NP (NP die Karten) (PP auf dem Tisch))))\",\n",
    "\"(S (NP Wir) (VP (VP (V trafen) (NP das Tier)) (PP im Schlafanzug)))\",\n",
    "\"(S (NP Wir) (VP (V trafen) (NP (NP das Tier) (PP im Schlafanzug))))\",\n",
    "\"(S (NP Sie) (VP (V kennt) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Sie) (VP (V mögen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Wir) (VP (V sehen) (NP (NP das Tier) (PP mit dem Fernglas))))\",\n",
    "\"(S (NP Du) (VP (V glaubst) (PP an den Weihnachtsmann)))\",\n",
    "]\n",
    "\n",
    "\n",
    "trees = []\n",
    "for treestring in treestrings:\n",
    "    trees.append(Tree.fromstring(treestring))\n",
    "    \n",
    "    \n",
    "#grammar induction:    \n",
    "productions = []\n",
    "S = nltk.Nonterminal('S')\n",
    "\n",
    "for tree in trees:\n",
    "    productions += tree.productions()\n",
    "\n",
    "grammar = nltk.induce_pcfg(S, productions)\n",
    "for production in grammar.productions():\n",
    "    print(production)    \n",
    "    \n",
    "#parse trees with grammar:    \n",
    "parser = nltk.ViterbiParser(grammar)\n",
    "     \n",
    "for tree in trees:\n",
    "    for parse in parser.parse(tree.leaves()): \n",
    "        print(parse)\n",
    "        parse.pretty_print(unicodelines=True) \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11.2 Übergangsbasierter Shift-Reduce-Dependency-Parser\n",
    "\n",
    "#### Gegeben sei folgender Dependenzgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"96ca16e6ef634b27953128cc303f9883-0\" class=\"displacy\" width=\"450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">b</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">c</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">d</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-96ca16e6ef634b27953128cc303f9883-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-96ca16e6ef634b27953128cc303f9883-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-96ca16e6ef634b27953128cc303f9883-0-1\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-96ca16e6ef634b27953128cc303f9883-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">LEFTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-96ca16e6ef634b27953128cc303f9883-0-2\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-96ca16e6ef634b27953128cc303f9883-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">RIGHTARC-?</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L358.0,92.0 342.0,92.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_nr = \"\"\"\n",
    "1 a 2 LEFTARC-?\n",
    "2 b 0 ROOT\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 2 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geben Sie eine deutschen oder englischen Satz an, der diese Dependenzstrukturanalyse erfüllt; geben Sie außerdem die Reihenfolge der Durchführung der REDUCE-Übergänge mit einem Shift-Reduce-Dependency-Parser an. \n",
    "\n",
    "#### (Ersetzen Sie ausschließlich die Buchstaben `a,b,c,d` mit entsprechenden Wörtern sowie das Fragezeichen mit der Angaben der Nummer der Durchführung des REDUCE-Schritts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sent_nr = \"\"\"\n",
    "1 a 2 LEFTARC-?\n",
    "2 b 0 ROOT\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 2 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (11.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sent_nr = \"\"\"\n",
    "1 a 2 LEFTARC-?\n",
    "2 b 0 ROOT\n",
    "3 c 4 LEFTARC-?\n",
    "4 d 2 RIGHTARC-?\n",
    "\"\"\"\n",
    "\n",
    "sent = transform_nr_conll(sent_nr)\n",
    "dg = DependencyGraph(sent)\n",
    "\n",
    "ex = displacy_dep_input(sent)\n",
    "html = displacy.render(ex, style=\"dep\", manual=True, options={'distance':100})\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Datengestützte Syntaxanalyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 12.1 Lexikalisierte CFG (mit Merkmalen)\n",
    "\n",
    "#### Gegeben sei folgende FCFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[]\n",
      "  (NP[] (N[] er))\n",
      "  (VP[] (V[] steigt) (PP[] (P[] auf) (NP[] (Det[] den) (N[] Berg)))))\n",
      "            S[]                     \n",
      " ┌───────────┴───┐                   \n",
      " │              VP[]                \n",
      " │     ┌─────────┴─────┐             \n",
      " │     │              PP[]          \n",
      " │     │     ┌─────────┴────┐        \n",
      "NP[]   │     │             NP[]     \n",
      " │     │     │         ┌────┴────┐   \n",
      "N[]   V[]   P[]      Det[]      N[] \n",
      " │     │     │         │         │   \n",
      " er  steigt auf       den       Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] PP[]\n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "    PP[]  -> P[] NP[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    P[]   -> \"auf\"\n",
    "    V[]   -> \"steigt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie über ein HEAD-Merkmal in der FCFG eine vollständige Kopfannotation durch.\n",
    "\n",
    "#### (Sie können sowohl die UD als auch die TIGER-Dependenzregeln verwenden.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse line 9: Det[DET] -> \"den\"\nError parsing feature structure\n    Det[DET] -> \"den\"\n           ^ Expected equals sign",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2249\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreentrances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2250\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36m_read_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2279\u001b[0m             \u001b[0mfstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_partial_featdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreentrances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36m_read_partial_featdict\u001b[0;34m(self, s, position, match, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"equals sign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('equals sign', 7)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1448\u001b[0m                 \u001b[0;31m# expand out the disjunctions on the RHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36m_read_production\u001b[0;34m(line, nonterm_parser, probabilistic)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;31m# Parse the left-hand side.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2252\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2253\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36m_error\u001b[0;34m(self, s, expected, position)\u001b[0m\n\u001b[1;32m   2466\u001b[0m         )\n\u001b[0;32m-> 2467\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error parsing feature structure\n    Det[DET] -> \"den\"\n           ^ Expected equals sign",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3088926be2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatureGrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgramstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatureChartParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, input, features, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    948\u001b[0m             )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         start, productions = read_grammar(\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstruct_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         )\n",
      "\u001b[0;32m~/Dokumente/syntax/venv_syntax/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to parse line %s: %s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlinenum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse line 9: Det[DET] -> \"den\"\nError parsing feature structure\n    Det[DET] -> \"den\"\n           ^ Expected equals sign"
     ]
    }
   ],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] PP[]\n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "    PP[]  -> P[] NP[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    P[]   -> \"auf\"\n",
    "    V[]   -> \"steigt\"    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)\n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "gramstring = r\"\"\"\n",
    "% start S\n",
    "    S[]   -> NP[] VP[]\n",
    "    VP[]  -> V[] PP[]\n",
    "    NP[]  -> Det[] N[]\n",
    "    NP[]  -> N[]\n",
    "    PP[]  -> P[] NP[]\n",
    "\n",
    "    Det[] -> \"den\"\n",
    "    N[]   -> \"er\"    \n",
    "    N[]   -> \"Berg\"\n",
    "    P[]   -> \"auf\"\n",
    "    V[]   -> \"steigt\"    \n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.grammar.FeatureGrammar.fromstring(gramstring)\n",
    "parser = nltk.parse.FeatureChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    print(tree)    \n",
    "    tree = Tree.fromstring(str(tree).replace(\", \",\",\"))\n",
    "    tree.pretty_print(unicodelines=True)\n",
    "    #display(tree)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 12.2 Parent Annotation (mit Symbolerweiterung)\n",
    "\n",
    "#### Gegeben sei folgende CFG für einen Satz mit PP-Komplement:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S                  \n",
      " ┌──────────┴───┐               \n",
      " │              VP             \n",
      " │    ┌─────────┴───┐           \n",
      " │    │             PP         \n",
      " │    │     ┌───────┴───┐       \n",
      " NP   │     │           NP     \n",
      " │    │     │       ┌───┴───┐   \n",
      " N    V     P      Det      N  \n",
      " │    │     │       │       │   \n",
      " er steigt auf     den     Berg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V PP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "    PP  -> P NP\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    P   -> \"auf\"\n",
    "    V   -> \"steigt\"        \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Führen Sie über Symbolerweiterung (mit `^` als Trennerzeichen) in der CFG eine vollständige *Parent Annotation* durch, wie Sie durch die Regelanwendungen im Syntaxbaum der Angabe impliziert ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "\n",
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V PP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "    PP  -> P NP\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    P   -> \"auf\"\n",
    "    V   -> \"steigt\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (12.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "sentence = \"er steigt auf den Berg\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP VP\n",
    "    VP  -> V PP\n",
    "    NP  -> Det N\n",
    "    NP  -> N\n",
    "    PP  -> P NP\n",
    "\n",
    "    Det -> \"den\"\n",
    "    N   -> \"er\"    \n",
    "    N   -> \"Berg\"\n",
    "    P   -> \"auf\"\n",
    "    V   -> \"steigt\"    \n",
    "\n",
    "###########ERGAENZTE REGELN:    \n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar,trace=0)\n",
    "\n",
    "for tree in parser.parse(sentence.split()):\n",
    "    tree.pretty_print(unicodelines=True)    \n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Chunk-Analysen und Komplexität\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 13.1 Geben Sie einen folgende *IOB-Tag-Sequenz* einer NP-Chunk-Analyse erfüllenden deutschen Satz an, indem Sie die TODOs mit entsprechenden Strings ersetzen (nehmen Sie keine weiteren Änderungen vor).\n",
    "\n",
    "#### (Beachten Sie auch die gegebenen Satzzeichen bzgl. möglicher Satztypen und entsprechender Worstellung.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO_DO:\n",
    "iob_list = [\n",
    "(\"O\", TODO), \n",
    "(\"B-NP\", TODO),\n",
    "(\"B-NP\", TODO),\n",
    "(\"I-NP\", TODO),\n",
    "(\"I-NP\", TODO),    \n",
    "(\"B-NP\", TODO),\n",
    "(\"I-NP\", TODO),\n",
    "(\"O\", \"?\")\n",
    "]\n",
    "\n",
    "print(iob_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (13.1):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "iob_list = [\n",
    "(\"O\", TODO), \n",
    "(\"B-NP\", TODO),\n",
    "(\"B-NP\", TODO),\n",
    "(\"I-NP\", TODO),\n",
    "(\"I-NP\", TODO),    \n",
    "(\"B-NP\", TODO),\n",
    "(\"I-NP\", TODO),\n",
    "(\"O\", \"?\")\n",
    "]\n",
    "\n",
    "print(iob_list)\n",
    "</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " \n",
    " \n",
    "## 13.2 Verarbeitung syntaktischer Konstruktionen\n",
    "\n",
    "#### Gegeben sei folgende Liste von Sätzen und Satzfragmenten:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Max streicht das Haus\n",
      "1 Max ist der Katze begegnet\n",
      "2 der Mann, der die Katze, die auf dem Baum geklettert war, gerettet hat, wird ausgezeichnet\n",
      "3 der Mann wird ausgezeichnet, der die Katze gerettet hat, die auf dem Baum geklettert war\n",
      "4 dass wir ihm das Haus anstreichen helfen\n",
      "5 den Tanz lehren wir ihn zu tanzen\n",
      "6 dass wir ihn den Tanz zu tanzen lehren\n"
     ]
    }
   ],
   "source": [
    "constructions = [\n",
    "\"Max streicht das Haus\",    \n",
    "\"Max ist der Katze begegnet\",\n",
    "\"der Mann, der die Katze, die auf dem Baum geklettert war, gerettet hat, wird ausgezeichnet\",\n",
    "\"der Mann wird ausgezeichnet, der die Katze gerettet hat, die auf dem Baum geklettert war\", \n",
    "\"dass wir ihm das Haus anstreichen helfen\" ,\n",
    "\"den Tanz lehren wir ihn zu tanzen\",\n",
    "\"dass wir ihn den Tanz zu tanzen lehren\"    \n",
    "]\n",
    "\n",
    "for (i, item) in enumerate(constructions):\n",
    "    print(i, item)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wählen Sie aus dieser Liste (über den Listenindex) ein Element aus, das folgende syntaktische Struktur enthält (Zuordnung gemäß Matrikelnummer):\n",
    "\n",
    "\n",
    "\n",
    "- `Mnr 0-5:` ***center embedding*-Struktur** \n",
    "    - *(d.h. die Verarbeitung benötigt mindestens eine CFG)*\n",
    "\n",
    "\n",
    "- `Mnr 6-9:` ***long distance dependency***\n",
    "    - *(d.h. die Verarbeitung ist nur mit einem nicht-projektiven Dependency-Parser möglich)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'den Tanz lehren wir ihn zu tanzen'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO_DO:\n",
    "constructions[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[zurück zur Übersicht](#Übersicht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ursprüngliche Angabe (13.2):*\n",
    "\n",
    "<div style=\"border: 2px solid gray;font-size:80%; background-color: #F0F0F0; line-height: 1.5;\">\n",
    "<code>\n",
    "constructions[TODO]\n",
    "</code>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_syntax",
   "language": "python",
   "name": "venv_syntax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
